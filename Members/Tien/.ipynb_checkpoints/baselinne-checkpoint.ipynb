{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>composers_name</th>\n",
       "      <th>composers_id</th>\n",
       "      <th>release_time</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.tuning_frequency</th>\n",
       "      <th>tonal.tuning_nontempered_energy_ratio</th>\n",
       "      <th>tonal.chords_key</th>\n",
       "      <th>tonal.chords_scale</th>\n",
       "      <th>tonal.key_edma.key</th>\n",
       "      <th>tonal.key_edma.scale</th>\n",
       "      <th>tonal.key_krumhansl.key</th>\n",
       "      <th>tonal.key_krumhansl.scale</th>\n",
       "      <th>tonal.key_temperley.key</th>\n",
       "      <th>tonal.key_temperley.scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073748245</td>\n",
       "      <td>Đêm Chôn Dầu Vượt Biển</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>551</td>\n",
       "      <td>Châu Đình An</td>\n",
       "      <td>5765</td>\n",
       "      <td>2017-10-01 22:07:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>0.601478</td>\n",
       "      <td>D</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1073751978</td>\n",
       "      <td>Mùa Thu Trong Mưa</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Trường Sa</td>\n",
       "      <td>100105</td>\n",
       "      <td>2017-10-01 20:58:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.193115</td>\n",
       "      <td>0.944516</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1073835561</td>\n",
       "      <td>Rồi Ánh Trăng Tan</td>\n",
       "      <td>Lưu Bích</td>\n",
       "      <td>450</td>\n",
       "      <td>Quốc Bảo</td>\n",
       "      <td>4355</td>\n",
       "      <td>2017-11-01 18:16:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.193115</td>\n",
       "      <td>0.957651</td>\n",
       "      <td>Bb</td>\n",
       "      <td>major</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1073856553</td>\n",
       "      <td>Còn Thương Rau Đắng Mọc Sau Hè</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>551</td>\n",
       "      <td>Bắc Sơn</td>\n",
       "      <td>7686</td>\n",
       "      <td>2017-11-01 17:36:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>441.272583</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>G</td>\n",
       "      <td>minor</td>\n",
       "      <td>G</td>\n",
       "      <td>minor</td>\n",
       "      <td>G</td>\n",
       "      <td>minor</td>\n",
       "      <td>G</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1073929630</td>\n",
       "      <td>Người Điên Biết Yêu</td>\n",
       "      <td>Như Loan</td>\n",
       "      <td>513</td>\n",
       "      <td>Lê Minh Kha</td>\n",
       "      <td>100466</td>\n",
       "      <td>2017-11-01 17:49:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.946167</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1073929880</td>\n",
       "      <td>Đàn Bà</td>\n",
       "      <td>Don Hồ</td>\n",
       "      <td>6515</td>\n",
       "      <td>Song Ngọc</td>\n",
       "      <td>100288</td>\n",
       "      <td>2017-10-01 21:33:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>436.960693</td>\n",
       "      <td>0.768609</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1073949310</td>\n",
       "      <td>Yêu Một Người Sống Bên Một Người</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Hoài An</td>\n",
       "      <td>100133</td>\n",
       "      <td>2017-11-01 18:27:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>442.548920</td>\n",
       "      <td>0.701749</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9078</td>\n",
       "      <td>1073994292</td>\n",
       "      <td>Giấc Mơ Mình Em</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Minh Vy</td>\n",
       "      <td>100019</td>\n",
       "      <td>2017-11-01 18:27:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>441.782684</td>\n",
       "      <td>0.659616</td>\n",
       "      <td>Bb</td>\n",
       "      <td>major</td>\n",
       "      <td>Bb</td>\n",
       "      <td>major</td>\n",
       "      <td>Bb</td>\n",
       "      <td>major</td>\n",
       "      <td>Bb</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1073994297</td>\n",
       "      <td>Mất Nhau Trong Đời</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Huỳnh Nhật Tân</td>\n",
       "      <td>100306</td>\n",
       "      <td>2017-11-01 18:27:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.193115</td>\n",
       "      <td>0.913990</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1073994298</td>\n",
       "      <td>Những Ân Tình Xưa</td>\n",
       "      <td>Minh Tuyết, Bằng Kiều</td>\n",
       "      <td>455.306</td>\n",
       "      <td>Hoài An</td>\n",
       "      <td>100133</td>\n",
       "      <td>2017-11-01 18:27:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>437.971466</td>\n",
       "      <td>0.726335</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1073994300</td>\n",
       "      <td>Ở Nơi Đó Em Cười</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Hoài An</td>\n",
       "      <td>100133</td>\n",
       "      <td>2017-11-01 18:27:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>437.718536</td>\n",
       "      <td>0.732484</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1074011942</td>\n",
       "      <td>Tình Chấp Nhận</td>\n",
       "      <td>Quỳnh Vi</td>\n",
       "      <td>7928</td>\n",
       "      <td>Trần Đức</td>\n",
       "      <td>7898</td>\n",
       "      <td>2017-11-01 18:49:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>440.763123</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1074239565</td>\n",
       "      <td>Rồi Mai Tôi Đưa Em</td>\n",
       "      <td>Trần Thái Hòa</td>\n",
       "      <td>901</td>\n",
       "      <td>Trường Sa</td>\n",
       "      <td>100105</td>\n",
       "      <td>2017-10-01 20:58:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>440.508636</td>\n",
       "      <td>0.673602</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1074245455</td>\n",
       "      <td>Thiên Đàng Đánh Mất</td>\n",
       "      <td>Dương Triệu Vũ</td>\n",
       "      <td>5072</td>\n",
       "      <td>Nguyễn Hồng Thuận</td>\n",
       "      <td>9140</td>\n",
       "      <td>2017-11-01 18:42:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>443.316437</td>\n",
       "      <td>0.793990</td>\n",
       "      <td>G</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>major</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1074245511</td>\n",
       "      <td>Vai Phụ</td>\n",
       "      <td>Loan Châu</td>\n",
       "      <td>827</td>\n",
       "      <td>Phạm Khải Tuấn</td>\n",
       "      <td>100116</td>\n",
       "      <td>2017-10-01 21:22:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.193115</td>\n",
       "      <td>0.983561</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>1074247432</td>\n",
       "      <td>Tình Nhỏ Mau Quên</td>\n",
       "      <td>Quang Lê, Hương Thủy</td>\n",
       "      <td>828.87</td>\n",
       "      <td>Hàn Châu</td>\n",
       "      <td>100406</td>\n",
       "      <td>2017-10-01 22:32:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>441.272583</td>\n",
       "      <td>0.738260</td>\n",
       "      <td>Eb</td>\n",
       "      <td>minor</td>\n",
       "      <td>Eb</td>\n",
       "      <td>minor</td>\n",
       "      <td>Eb</td>\n",
       "      <td>minor</td>\n",
       "      <td>Eb</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>9079</td>\n",
       "      <td>1074250503</td>\n",
       "      <td>Rồi 30 Năm Qua</td>\n",
       "      <td>Tâm Đoan</td>\n",
       "      <td>518</td>\n",
       "      <td>Nhật Ngân</td>\n",
       "      <td>100218</td>\n",
       "      <td>2017-10-01 22:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>440.508636</td>\n",
       "      <td>0.702865</td>\n",
       "      <td>F#</td>\n",
       "      <td>minor</td>\n",
       "      <td>B</td>\n",
       "      <td>major</td>\n",
       "      <td>B</td>\n",
       "      <td>major</td>\n",
       "      <td>B</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>1074254689</td>\n",
       "      <td>Chơi Vơi Dòng Đời</td>\n",
       "      <td>Duy Linh</td>\n",
       "      <td>918</td>\n",
       "      <td>Huy Liêu</td>\n",
       "      <td>430572</td>\n",
       "      <td>2017-11-07 23:40:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.193115</td>\n",
       "      <td>0.961273</td>\n",
       "      <td>D</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>1074254690</td>\n",
       "      <td>Dòng Sông Quê Hương</td>\n",
       "      <td>Lan Phương</td>\n",
       "      <td>6517</td>\n",
       "      <td>Huy Liêu</td>\n",
       "      <td>430572</td>\n",
       "      <td>2017-11-07 23:43:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>0.676015</td>\n",
       "      <td>C#</td>\n",
       "      <td>major</td>\n",
       "      <td>C#</td>\n",
       "      <td>major</td>\n",
       "      <td>C#</td>\n",
       "      <td>major</td>\n",
       "      <td>C#</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>9080</td>\n",
       "      <td>1074254709</td>\n",
       "      <td>Hòa Bình Hoan Ca</td>\n",
       "      <td>Hùng Phú, Duy Linh</td>\n",
       "      <td>18241.918</td>\n",
       "      <td>Huy Liêu</td>\n",
       "      <td>430572</td>\n",
       "      <td>2017-11-07 23:47:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>...</td>\n",
       "      <td>436.960693</td>\n",
       "      <td>0.790986</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index          ID                             title  \\\n",
       "0       0  1073748245            Đêm Chôn Dầu Vượt Biển   \n",
       "1       1  1073751978                 Mùa Thu Trong Mưa   \n",
       "2       2  1073835561                 Rồi Ánh Trăng Tan   \n",
       "3       3  1073856553    Còn Thương Rau Đắng Mọc Sau Hè   \n",
       "4       4  1073929630               Người Điên Biết Yêu   \n",
       "5       5  1073929880                            Đàn Bà   \n",
       "6       6  1073949310  Yêu Một Người Sống Bên Một Người   \n",
       "7    9078  1073994292                   Giấc Mơ Mình Em   \n",
       "8       7  1073994297                Mất Nhau Trong Đời   \n",
       "9       8  1073994298                 Những Ân Tình Xưa   \n",
       "10      9  1073994300                  Ở Nơi Đó Em Cười   \n",
       "11     10  1074011942                    Tình Chấp Nhận   \n",
       "12     11  1074239565                Rồi Mai Tôi Đưa Em   \n",
       "13     12  1074245455               Thiên Đàng Đánh Mất   \n",
       "14     13  1074245511                           Vai Phụ   \n",
       "15     14  1074247432                 Tình Nhỏ Mau Quên   \n",
       "16   9079  1074250503                    Rồi 30 Năm Qua   \n",
       "17     15  1074254689                 Chơi Vơi Dòng Đời   \n",
       "18     16  1074254690               Dòng Sông Quê Hương   \n",
       "19   9080  1074254709                  Hòa Bình Hoan Ca   \n",
       "\n",
       "              artist_name  artist_id     composers_name composers_id  \\\n",
       "0               Như Quỳnh        551       Châu Đình An         5765   \n",
       "1              Minh Tuyết        455          Trường Sa       100105   \n",
       "2                Lưu Bích        450           Quốc Bảo         4355   \n",
       "3               Như Quỳnh        551            Bắc Sơn         7686   \n",
       "4                Như Loan        513        Lê Minh Kha       100466   \n",
       "5                  Don Hồ       6515          Song Ngọc       100288   \n",
       "6              Minh Tuyết        455            Hoài An       100133   \n",
       "7              Minh Tuyết        455            Minh Vy       100019   \n",
       "8              Minh Tuyết        455     Huỳnh Nhật Tân       100306   \n",
       "9   Minh Tuyết, Bằng Kiều    455.306            Hoài An       100133   \n",
       "10             Minh Tuyết        455            Hoài An       100133   \n",
       "11               Quỳnh Vi       7928           Trần Đức         7898   \n",
       "12          Trần Thái Hòa        901          Trường Sa       100105   \n",
       "13         Dương Triệu Vũ       5072  Nguyễn Hồng Thuận         9140   \n",
       "14              Loan Châu        827     Phạm Khải Tuấn       100116   \n",
       "15   Quang Lê, Hương Thủy     828.87           Hàn Châu       100406   \n",
       "16               Tâm Đoan        518          Nhật Ngân       100218   \n",
       "17               Duy Linh        918           Huy Liêu       430572   \n",
       "18             Lan Phương       6517           Huy Liêu       430572   \n",
       "19     Hùng Phú, Duy Linh  18241.918           Huy Liêu       430572   \n",
       "\n",
       "           release_time  label dataset  ...  tonal.tuning_frequency  \\\n",
       "0   2017-10-01 22:07:00    7.0   train  ...              440.000000   \n",
       "1   2017-10-01 20:58:00    3.0   train  ...              434.193115   \n",
       "2   2017-11-01 18:16:00    6.0   train  ...              434.193115   \n",
       "3   2017-11-01 17:36:00    2.0   train  ...              441.272583   \n",
       "4   2017-11-01 17:49:00    7.0   train  ...              434.946167   \n",
       "5   2017-10-01 21:33:00    3.0   train  ...              436.960693   \n",
       "6   2017-11-01 18:27:00    4.0   train  ...              442.548920   \n",
       "7   2017-11-01 18:27:00    NaN    test  ...              441.782684   \n",
       "8   2017-11-01 18:27:00    8.0   train  ...              434.193115   \n",
       "9   2017-11-01 18:27:00    4.0   train  ...              437.971466   \n",
       "10  2017-11-01 18:27:00    8.0   train  ...              437.718536   \n",
       "11  2017-11-01 18:49:00    5.0   train  ...              440.763123   \n",
       "12  2017-10-01 20:58:00    3.0   train  ...              440.508636   \n",
       "13  2017-11-01 18:42:00    9.0   train  ...              443.316437   \n",
       "14  2017-10-01 21:22:00    6.0   train  ...              434.193115   \n",
       "15  2017-10-01 22:32:00    1.0   train  ...              441.272583   \n",
       "16  2017-10-01 22:07:00    NaN    test  ...              440.508636   \n",
       "17  2017-11-07 23:40:00    9.0   train  ...              434.193115   \n",
       "18  2017-11-07 23:43:00    8.0   train  ...              440.000000   \n",
       "19  2017-11-07 23:47:00    NaN    test  ...              436.960693   \n",
       "\n",
       "   tonal.tuning_nontempered_energy_ratio tonal.chords_key tonal.chords_scale  \\\n",
       "0                               0.601478                D              major   \n",
       "1                               0.944516                C              minor   \n",
       "2                               0.957651               Bb              major   \n",
       "3                               0.796499                G              minor   \n",
       "4                               0.860068                A              minor   \n",
       "5                               0.768609                A              minor   \n",
       "6                               0.701749                D              minor   \n",
       "7                               0.659616               Bb              major   \n",
       "8                               0.913990                C              minor   \n",
       "9                               0.726335                A              minor   \n",
       "10                              0.732484                A              minor   \n",
       "11                              0.655899                A              minor   \n",
       "12                              0.673602                D              minor   \n",
       "13                              0.793990                G              minor   \n",
       "14                              0.983561                A              minor   \n",
       "15                              0.738260               Eb              minor   \n",
       "16                              0.702865               F#              minor   \n",
       "17                              0.961273                D              major   \n",
       "18                              0.676015               C#              major   \n",
       "19                              0.790986                A              minor   \n",
       "\n",
       "   tonal.key_edma.key tonal.key_edma.scale  tonal.key_krumhansl.key  \\\n",
       "0                   G                major                        G   \n",
       "1                   C                minor                        C   \n",
       "2                   D                minor                        D   \n",
       "3                   G                minor                        G   \n",
       "4                   D                minor                        D   \n",
       "5                   D                minor                        A   \n",
       "6                   A                minor                        A   \n",
       "7                  Bb                major                       Bb   \n",
       "8                   C                minor                        C   \n",
       "9                   A                minor                        A   \n",
       "10                  D                minor                        D   \n",
       "11                  A                minor                        A   \n",
       "12                  D                minor                        D   \n",
       "13                  A                major                        A   \n",
       "14                  A                minor                        A   \n",
       "15                 Eb                minor                       Eb   \n",
       "16                  B                major                        B   \n",
       "17                  G                major                        G   \n",
       "18                 C#                major                       C#   \n",
       "19                  G                major                        G   \n",
       "\n",
       "   tonal.key_krumhansl.scale  tonal.key_temperley.key  \\\n",
       "0                      major                        G   \n",
       "1                      minor                        C   \n",
       "2                      minor                        D   \n",
       "3                      minor                        G   \n",
       "4                      minor                        D   \n",
       "5                      minor                        A   \n",
       "6                      minor                        A   \n",
       "7                      major                       Bb   \n",
       "8                      minor                        C   \n",
       "9                      minor                        A   \n",
       "10                     minor                        A   \n",
       "11                     minor                        A   \n",
       "12                     minor                        D   \n",
       "13                     major                        F   \n",
       "14                     minor                        A   \n",
       "15                     minor                       Eb   \n",
       "16                     major                        B   \n",
       "17                     major                        G   \n",
       "18                     major                       C#   \n",
       "19                     major                        G   \n",
       "\n",
       "    tonal.key_temperley.scale  \n",
       "0                       major  \n",
       "1                       minor  \n",
       "2                       minor  \n",
       "3                       minor  \n",
       "4                       minor  \n",
       "5                       minor  \n",
       "6                       minor  \n",
       "7                       major  \n",
       "8                       minor  \n",
       "9                       minor  \n",
       "10                      minor  \n",
       "11                      minor  \n",
       "12                      minor  \n",
       "13                      major  \n",
       "14                      minor  \n",
       "15                      minor  \n",
       "16                      major  \n",
       "17                      major  \n",
       "18                      major  \n",
       "19                      major  \n",
       "\n",
       "[20 rows x 137 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "TRAININFO = \"/data/HitSongPrediction/train_info.tsv\"\n",
    "TRAINRANK =  \"/data/HitSongPrediction/train_rank.csv\"\n",
    "TESTINFO = \"/data/HitSongPrediction/test_info.tsv\"\n",
    "SUBMISSION = \"/data/HitSongPrediction/submission.csv\"\n",
    "\n",
    "# Prepare data\n",
    "df_i = pd.read_csv(TRAININFO, delimiter='\\t',encoding='utf-8')\n",
    "df_r = pd.read_csv(TRAINRANK)\n",
    "df_i_train = df_i.merge(df_r, left_on='ID', right_on='ID')\n",
    "df_i_train[\"dataset\"] = \"train\"\n",
    "\n",
    "df_i_test = pd.read_csv(TESTINFO, delimiter='\\t',encoding='utf-8')\n",
    "df_i_test[\"label\"] = np.nan\n",
    "df_i_test[\"dataset\"] = \"test\"\n",
    "\n",
    "df = pd.concat([df_i_train, df_i_test])\n",
    "df_track_info = pd.read_csv(\"../../csv/all_track_info.csv\")\n",
    "df = df.merge(df_track_info, left_on='ID', right_on='ID')\n",
    "df_audio_features = pd.read_csv(\"../../csv/all_track_audio_features.csv\")\n",
    "df =df.merge(df_audio_features,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "\n",
    "# Sort by ID\n",
    "df = df.sort_values(by=['ID'])\n",
    "df= df.reset_index()\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 0.24038838760298156 ratio is nan album\n",
      "There is 0.0017653981953707335 ratio is nan genre\n",
      "There is 0.24038838760298156 ratio is nan album_artist\n",
      "There is 0.0007846214201647705 ratio is nan track\n",
      "There is 0.6722244017261672 ratio is nan lyric\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Fill nan album\n",
    "print(\"There is {} ratio is nan album\".format(len(df[df[\"album\"].isnull()])/len(df)))\n",
    "df[\"album\"]  = df[\"album\"].fillna(\"\")\n",
    "df[\"len_album_name\"] = df[\"album\"].apply(lambda x: len(x.split(\" \")))\n",
    "df[\"isRemixAlbum\"] = [ 1 if \"Remix\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isOSTAlbum\"] = [ 1 if \"OST\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isSingleAlbum\"] = [ 1 if \"Single\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isBeatAlbum\"] = [ 1 if \"Beat\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isTopHitAlbum\"] = [ 1 if \"Top Hits\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isCoverAlbum\"] = [ 1 if \"Cover\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isEPAlbum\"] = [ 1 if \"EP\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isLienKhucAlbum\"] = [ 1 if \"Liên Khúc\" in t else 0 for t in df[\"album\"]]\n",
    "\n",
    "df[\"album_name_is_title_name\"]= [1 if r.title in r.album  else 0 for i,r in df.iterrows() ]\n",
    "df[\"album\"] = df[\"album\"].astype('category')\n",
    "df[\"album\"] =  df[\"album\"].cat.codes\n",
    "#It seems like all songs on albums release at the same time, so groupby by release_time will create album \n",
    "df[\"album_right\"] = df.groupby(df.release_time).ngroup().astype(\"category\").cat.codes\n",
    "\n",
    "df[\"artist_name_cat\"] = df[\"artist_name\"].astype('category')\n",
    "df[\"artist_name_cat\"] =  df[\"artist_name_cat\"].cat.codes\n",
    "df[\"composers_name_cat\"] = df[\"composers_name\"].astype('category')\n",
    "df[\"composers_name_cat\"] =  df[\"composers_name_cat\"].cat.codes\n",
    "df[\"copyright_cat\"] = df[\"copyright\"].astype('category')\n",
    "df[\"copyright_cat\"] =  df[\"copyright_cat\"].cat.codes\n",
    "\n",
    "import re\n",
    "def get_min_artist_id(s):\n",
    "    ps = re.split(',|\\.',s)\n",
    "    ps = [int(p) for p in ps]\n",
    "    return np.min(ps)\n",
    "\n",
    "def get_max_artist_id(s):\n",
    "    ps = re.split(',|\\.',s)\n",
    "    ps = [int(p) for p in ps]\n",
    "    return np.max(ps)\n",
    "\n",
    "df[\"artist_id_min\"]=  df[\"artist_id\"].apply(lambda x: get_min_artist_id(x))\n",
    "df[\"artist_id_min_cat\"] = df[\"artist_id_min\"].astype('category')\n",
    "df[\"artist_id_min_cat\"] =  df[\"artist_id_min_cat\"].cat.codes\n",
    "\n",
    "df[\"composers_id_min\"]=  df[\"composers_id\"].apply(lambda x: get_min_artist_id(x))\n",
    "df[\"composers_id_min_cat\"] = df[\"composers_id_min\"].astype('category')\n",
    "df[\"composers_id_min_cat\"] =  df[\"composers_id_min_cat\"].cat.codes\n",
    "\n",
    "df[\"artist_id_max\"]=  df[\"artist_id\"].apply(lambda x: get_max_artist_id(x))\n",
    "df[\"artist_id_max_cat\"] = df[\"artist_id_max\"].astype('category')\n",
    "df[\"artist_id_max_cat\"] =  df[\"artist_id_max_cat\"].cat.codes\n",
    "\n",
    "df[\"composers_id_max\"]=  df[\"composers_id\"].apply(lambda x: get_max_artist_id(x))\n",
    "df[\"composers_id_max_cat\"] = df[\"composers_id_max\"].astype('category')\n",
    "df[\"composers_id_max_cat\"] =  df[\"composers_id_max_cat\"].cat.codes\n",
    "\n",
    "#New feature\n",
    "# df[\"group_album_artist_id_min_cat\"] = df.groupby([\"album\",\"artist_id_min_cat\"]).ngroup()\n",
    "# df[\"group_album_artist_id_min_cat\"] = df[\"group_album_artist_id_min_cat\"].astype(\"category\").cat.codes\n",
    "# df[\"group_album_artist_id_max_cat\"] = df.groupby([\"album\",\"artist_id_max_cat\"]).ngroup()\n",
    "# df[\"group_album_artist_id_max_cat\"] = df[\"group_album_artist_id_max_cat\"].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "# Fill genre\n",
    "print(\"There is {} ratio is nan genre\".format(len(df[df[\"genre\"].isnull()])/len(df)))\n",
    "df[\"genre\"]  = df[\"genre\"].fillna(\"No genre\")\n",
    "df[\"genre\"] = df[\"genre\"].astype('category')\n",
    "df[\"genre\"] =  df[\"genre\"].cat.codes\n",
    "\n",
    "# Fill album_artist\n",
    "print(\"There is {} ratio is nan album_artist\".format(len(df[df[\"album_artist\"].isnull()])/len(df)))\n",
    "df[\"album_artist\"]  = df[\"album_artist\"].fillna(\"No album_artist\")\n",
    "df[\"album_artist_contain_artistname\"]= [1 if r.album_artist in r.artist_name  else 0 for i,r in df.iterrows() ]\n",
    "df[\"album_artist\"] = df[\"album_artist\"].astype('category')\n",
    "df[\"album_artist\"] =  df[\"album_artist\"].cat.codes\n",
    "\n",
    "# Fill track\n",
    "print(\"There is {} ratio is nan track\".format(len(df[df[\"track\"].isnull()])/len(df)))\n",
    "df[\"track\"]  = df[\"track\"].fillna(\"(1, 1)\")\n",
    "df[\"istrack11\"] = df[\"track\"] == \"(1, 1)\"\n",
    "def tracknum_to_value(track_num):\n",
    "    try:\n",
    "        \n",
    "        track_num = make_tuple(track_num)\n",
    "        if track_num[0] is not None:\n",
    "            return float(track_num[0]) / float(track_num[1])\n",
    "        else:\n",
    "            return 1.0\n",
    "    except:\n",
    "        return 1.0\n",
    "\n",
    "df[\"track\"] = df[\"track\"].apply(lambda t: tracknum_to_value(t))\n",
    "\n",
    "\n",
    "# Fill lyric\n",
    "print(\"There is {} ratio is nan lyric\".format(len(df[df[\"lyric\"].isnull()])/len(df)))\n",
    "df[\"lyric\"]  = df[\"lyric\"].fillna(\"\")\n",
    "df[\"islyric\"] = df[\"lyric\"].apply(lambda x:  True if len(x)  else False)\n",
    "df[\"num_line_lyric\"] = df[\"lyric\"].apply(lambda x : len(x.split(\"\\r\")))\n",
    "\n",
    "\n",
    "#--------------------------------------------------------\n",
    "from dateutil import relativedelta\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ast import literal_eval as make_tuple\n",
    "df['no_artist'] = df.artist_name.apply(lambda x: len(x.split(\",\")))\n",
    "df['no_composer'] = df.composers_name.apply(lambda x: len(x.split(\",\")))\n",
    "df[\"freq_artist\"] = df.groupby('artist_id')['artist_id'].transform('count').astype('float')\n",
    "df[\"freq_composer\"] = df.groupby('composers_id')['composers_id'].transform('count').astype('float')\n",
    "df[\"freq_artist_min\"] = df.groupby('artist_id_min_cat')['artist_id_min_cat'].transform('count').astype('float')\n",
    "df[\"freq_composer_min\"] = df.groupby('composers_id_min_cat')['composers_id_min_cat'].transform('count').astype('float')\n",
    "\n",
    "df[\"num_album_per_min_artist\"] = df.groupby(['artist_id_min_cat','album'])['album'].transform('count').astype('float')\n",
    "df[\"num_album_per_min_composer\"] = df.groupby(['composers_id_min','album'])['album'].transform('count').astype('float')\n",
    "\n",
    "\n",
    "df[\"datetime\"] = pd.to_datetime(df.release_time)\n",
    "df[\"year\"] = df[\"datetime\"].dt.year\n",
    "df[\"month\"] = df[\"datetime\"].dt.month\n",
    "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "df[\"day\"] = df[\"datetime\"].dt.day\n",
    "df[\"dayofyear\"] = df[\"datetime\"].dt.dayofyear\n",
    "df[\"weekday\"] = df[\"datetime\"].dt.weekday\n",
    "from datetime import date \n",
    "import holidays \n",
    "\n",
    "in_holidays = holidays.HolidayBase() \n",
    "for i in range(26,32):\n",
    "    in_holidays.append(str(i)+'-01-2017')\n",
    "in_holidays.append('01-02-2017')\n",
    "for i in range(14,21):\n",
    "    in_holidays.append(str(i)+'-02-2018')\n",
    "in_holidays.append('30-04-2017')\n",
    "in_holidays.append('30-04-2018')\n",
    "in_holidays.append('01-01-2017')\n",
    "in_holidays.append('01-01-2018')\n",
    "in_holidays.append('14-02-2017')\n",
    "in_holidays.append('14-02-2018')\n",
    "in_holidays.append('08-03-2017')\n",
    "in_holidays.append('08-03-2018')\n",
    "in_holidays.append('01-05-2017')\n",
    "in_holidays.append('01-05-2018')\n",
    "in_holidays.append('06-04-2017')\n",
    "in_holidays.append('25-04-2018')\n",
    "in_holidays.append('01-06-2017')\n",
    "in_holidays.append('01-06-2018')\n",
    "in_holidays.append('04-10-2017')\n",
    "in_holidays.append('24-09-2018')\n",
    "in_holidays.append('20-10-2017')\n",
    "in_holidays.append('20-10-2018')\n",
    "in_holidays.append('20-11-2017')\n",
    "in_holidays.append('20-11-2018')\n",
    "in_holidays.append('24-12-2017')\n",
    "in_holidays.append('24-12-2018')\n",
    "df['isHoliday'] = df.release_time.apply(lambda x: x in in_holidays)\n",
    "\n",
    "\n",
    "\n",
    "df[\"len_of_songname\"] = df[\"title\"].apply(lambda x: len(x.split(\" \")))\n",
    "df[\"isRemix\"] = [ 1 if \"Remix\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isOST\"] = [ 1 if \"OST\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isBeat\"] = [ 1 if \"Beat\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isVersion\"] = [ 1 if \"Version\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isCover\"] = [ 1 if \"Cover\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isLienKhuc\"] = [ 1 if \"Liên Khúc\" in t else 0 for t in df[\"title\"]]\n",
    "\n",
    "\n",
    "\n",
    "def find_num_song_release_in_final_month(df, day):\n",
    "    month5th = day + relativedelta.relativedelta(months=5)\n",
    "    month6th = day + relativedelta.relativedelta(months=6)  \n",
    "    return len(df.datetime[(df.datetime >= month5th)&(df.datetime<=month6th)])\n",
    "\n",
    "\n",
    "\n",
    "df[\"num_song_release_in_final_month\"] = df.datetime.apply(lambda d:find_num_song_release_in_final_month(df ,d))\n",
    "\n",
    "\n",
    "df[\"day_release\"] = df.groupby([\"year\",\"dayofyear\"]).ngroup().astype(\"category\").cat.codes\n",
    "df[\"numsongInAlbum\"] = df.groupby(\"album_right\")[\"album_right\"].transform(\"count\")\n",
    "df[\"isSingleAlbum_onesong\"]= df[\"isSingleAlbum\"] & (df[\"numsongInAlbum\"]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def split_id(s):\n",
    "    return re.split(',|\\.',s)\n",
    "\n",
    "m = df.artist_id.unique()\n",
    "idx_lst = []\n",
    "for idx in m:\n",
    "    ps = split_id(idx)\n",
    "    for i in ps:\n",
    "        idx_lst.append(i)\n",
    "        \n",
    "id_lst = list(set(idx_lst))\n",
    "\n",
    "def condition(df, artist_id):\n",
    "    r = df.artist_id.apply(lambda x: artist_id in split_id(x))\n",
    "    return r\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "data= [df_train[condition(df_train, artist_id)].label.agg([\"mean\",\"std\",\"count\"]) for artist_id in id_lst]\n",
    "new_df = pd.DataFrame(data=data)\n",
    "new_df[\"artist_id\"] =  id_lst\n",
    "\n",
    "new_df.dropna(inplace=True)\n",
    "new_df.set_index('artist_id', inplace=True)\n",
    "art_dict = new_df.to_dict()\n",
    "\n",
    "def best_mean_id(values):\n",
    "    ids = split_id(values)\n",
    "    temp_mean = 10\n",
    "    temp_id = str(min([int(a) for a in ids]))\n",
    "    for id in ids:\n",
    "        try:\n",
    "            if art_dict['mean'][id] < temp_mean:\n",
    "                temp_mean = art_dict['mean'][id]\n",
    "                temp_id = id\n",
    "        except:\n",
    "            temp_mean = temp_mean\n",
    "            temp_id = temp_id\n",
    "    return temp_id\n",
    "\n",
    "df['artist_mean_id'] = df['artist_id'].apply(best_mean_id)\n",
    "\n",
    "def best_std_id(values):\n",
    "    ids = split_id(values)\n",
    "    temp_std = 10\n",
    "    temp_id = str(min([int(a) for a in ids]))\n",
    "    for id in ids:\n",
    "        try:\n",
    "            if art_dict['std'][id] < temp_std:\n",
    "                temp_std = art_dict['std'][id]\n",
    "                temp_id = id\n",
    "        except:\n",
    "            temp_std = temp_std\n",
    "            temp_id = temp_id\n",
    "    return temp_id\n",
    "\n",
    "df['artist_std_id'] = df['artist_id'].apply(best_std_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['artist_mean_id'] = df['artist_mean_id'].astype('category')\n",
    "df['artist_std_id'] = df['artist_std_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def split_id(s):\n",
    "    return re.split(',|\\.',s)\n",
    "\n",
    "m = df.composers_id.unique()\n",
    "idx_lst = []\n",
    "for idx in m:\n",
    "    ps = split_id(idx)\n",
    "    for i in ps:\n",
    "        idx_lst.append(i)\n",
    "        \n",
    "id_lst = list(set(idx_lst))\n",
    "\n",
    "def condition(df, composers_id):\n",
    "    r = df.composers_id.apply(lambda x: composers_id in split_id(x))\n",
    "    return r\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "data= [df_train[condition(df_train, composers_id)].label.agg([\"mean\",\"std\",\"count\"]) for composers_id in id_lst]\n",
    "new_df = pd.DataFrame(data=data)\n",
    "new_df[\"composers_id\"] =  id_lst\n",
    "\n",
    "new_df.dropna(inplace=True)\n",
    "new_df.set_index('composers_id', inplace=True)\n",
    "art_dict = new_df.to_dict()\n",
    "\n",
    "def best_mean_id(values):\n",
    "    ids = split_id(values)\n",
    "    temp_mean = 10\n",
    "    temp_id = str(min([int(a) for a in ids]))\n",
    "    for id in ids:\n",
    "        try:\n",
    "            if art_dict['mean'][id] < temp_mean:\n",
    "                temp_mean = art_dict['mean'][id]\n",
    "                temp_id = id\n",
    "        except:\n",
    "            temp_mean = temp_mean\n",
    "            temp_id = temp_id\n",
    "    return temp_id\n",
    "\n",
    "df['composers_mean_id'] = df['composers_id'].apply(best_mean_id)\n",
    "\n",
    "def best_std_id(values):\n",
    "    ids = split_id(values)\n",
    "    temp_std = 10\n",
    "    temp_id = str(min([int(a) for a in ids]))\n",
    "    for id in ids:\n",
    "        try:\n",
    "            if art_dict['std'][id] < temp_std:\n",
    "                temp_std = art_dict['std'][id]\n",
    "                temp_id = id\n",
    "        except:\n",
    "            temp_std = temp_std\n",
    "            temp_id = temp_id\n",
    "    return temp_id\n",
    "\n",
    "df['composers_std_id'] = df['composers_id'].apply(best_std_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['composers_mean_id'] = df['composers_mean_id'].astype('category')\n",
    "df['composers_std_id'] = df['composers_std_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['composers_name_catfreq_artist_min'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9e3ecb4eab17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fold {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtrn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchosen_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchosen_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['composers_name_catfreq_artist_min'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "chosen_features = [ \"album_right\", \"istrack11\", \"no_artist\", \"no_composer\",\"freq_artist\", \"freq_composer\",\"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "                   \"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "                  \"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "                  \"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "                  \"isBeatAlbum\", \"isCoverAlbum\", \"artist_name_cat\",\"composers_name_cat\",\"copyright_cat\" ,\n",
    "                  \"artist_id_min_cat\",  \"artist_id_max_cat\", \"composers_name_cat\",\n",
    "                   \"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\"isHoliday\",\n",
    "                  \"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "                   \"numsongInAlbum\",\"isSingleAlbum_onesong\",\"artist_mean_id\", \"artist_std_id\"  ]\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "df_test = df[df.dataset==\"test\"]\n",
    "\n",
    "param = {\n",
    "    'bagging_freq': 20,          \n",
    "    'bagging_fraction': 0.95,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             'feature_fraction': 0.1,     'learning_rate': 0.001,\n",
    "    'max_depth': -1,             'metric':'root_mean_squared_error', 'min_data_in_leaf': 5,   \n",
    "       'num_leaves': 50,            \n",
    "    'num_threads': 8,              'tree_learner': 'serial',   'objective': 'regression',\n",
    "    'reg_alpha': 0.1002650970728192, 'reg_lambda': 0.1003427518866501,'verbosity': 1,\n",
    "    \"seed\": 99999\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=99999)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "labels= df_train.label\n",
    "# fig, axes = plt.subplots(5, 1, figsize=(10, 10*5))\n",
    "# axes = axes.flat\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train.label.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][chosen_features], label=labels.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][chosen_features], label=labels.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 20000)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][chosen_features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(df_test[chosen_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.60434 \n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "print(\"RMSE: {:<8.5f}\".format(sqrt(mean_squared_error(df_train.label, oof))))\n",
    "\n",
    "sub = pd.DataFrame({\"ID\": df_test.ID.values})\n",
    "sub[\"label\"] = predictions\n",
    "sub.to_csv(\"submission_lightgbm.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
