{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "from base_tokenizer import BaseTokenizer\n",
    "from utils import load_n_grams\n",
    "from dict_models import LongMatchingTokenizer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAININFO = \"../data/train_info.tsv\"\n",
    "TRAINRANK =  \"../data/train_rank.csv\"\n",
    "TESTINFO = \"../data/test_info.tsv\"\n",
    "Track_info = \"../data/all_track_info.csv\"\n",
    "Audio_info = \"../data/all_track_audio_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>lyric</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073748245</td>\n",
       "      <td>Đêm Chôn Dầu Vượt Biển</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>Đêm nay anh gánh dầu ra biển anh chôn \\r\\nAnh ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073751978</td>\n",
       "      <td>Mùa Thu Trong Mưa</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>Chiều mưa không có em\\r\\nbờ đá công viên âm th...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073835561</td>\n",
       "      <td>Rồi Ánh Trăng Tan</td>\n",
       "      <td>Lưu Bích</td>\n",
       "      <td>Rồi ánh trăng cũng đang tan dần\\r\\nRồi ước mơ ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073856553</td>\n",
       "      <td>Còn Thương Rau Đắng Mọc Sau Hè</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>Nắng hạ đi Mây trôi lang thang cho hạ buồn Coi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073929630</td>\n",
       "      <td>Người Điên Biết Yêu</td>\n",
       "      <td>Như Loan</td>\n",
       "      <td>Ai trong tình yêu, ai không mơ mộng?\\n\\nNgu ng...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                           title artist_name  \\\n",
       "0  1073748245          Đêm Chôn Dầu Vượt Biển   Như Quỳnh   \n",
       "1  1073751978               Mùa Thu Trong Mưa  Minh Tuyết   \n",
       "2  1073835561               Rồi Ánh Trăng Tan    Lưu Bích   \n",
       "3  1073856553  Còn Thương Rau Đắng Mọc Sau Hè   Như Quỳnh   \n",
       "4  1073929630             Người Điên Biết Yêu    Như Loan   \n",
       "\n",
       "                                               lyric  label dataset  \n",
       "0  Đêm nay anh gánh dầu ra biển anh chôn \\r\\nAnh ...    7.0   train  \n",
       "1  Chiều mưa không có em\\r\\nbờ đá công viên âm th...    3.0   train  \n",
       "2  Rồi ánh trăng cũng đang tan dần\\r\\nRồi ước mơ ...    6.0   train  \n",
       "3  Nắng hạ đi Mây trôi lang thang cho hạ buồn Coi...    2.0   train  \n",
       "4  Ai trong tình yêu, ai không mơ mộng?\\n\\nNgu ng...    7.0   train  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i = pd.read_csv(TRAININFO, delimiter='\\t',encoding='utf-8')\n",
    "df_r = pd.read_csv(TRAINRANK)\n",
    "df_i_train = df_i.merge(df_r, left_on='ID', right_on='ID')\n",
    "df_i_train[\"dataset\"] = \"train\"\n",
    "\n",
    "df_i_test = pd.read_csv(TESTINFO, delimiter='\\t',encoding='utf-8')\n",
    "df_i_test[\"label\"] = np.nan\n",
    "df_i_test[\"dataset\"] = \"test\"\n",
    "\n",
    "df = pd.concat([df_i_train, df_i_test])\n",
    "df_track_info = pd.read_csv(Track_info)\n",
    "df = df.merge(df_track_info, left_on='ID', right_on='ID')\n",
    "df_audio_features = pd.read_csv(Audio_info)\n",
    "df =df.merge(df_audio_features,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "df = df[['ID','title','artist_name','lyric','label','dataset']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2981, 6)\n",
      "(2488, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tien/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>lyric</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073748245</td>\n",
       "      <td>Đêm Chôn Dầu Vượt Biển</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>đêm nay anh gánh dầu ra biển anh chôn anh chôn...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073751978</td>\n",
       "      <td>Mùa Thu Trong Mưa</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>chiều mưa không có em bờ đá công viên âm thầm ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073835561</td>\n",
       "      <td>Rồi Ánh Trăng Tan</td>\n",
       "      <td>Lưu Bích</td>\n",
       "      <td>rồi ánh trăng cũng đang tan dần rồi ước mơ cũn...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073856553</td>\n",
       "      <td>Còn Thương Rau Đắng Mọc Sau Hè</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>nắng hạ đi mây trôi lang thang cho hạ buồn coi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073929630</td>\n",
       "      <td>Người Điên Biết Yêu</td>\n",
       "      <td>Như Loan</td>\n",
       "      <td>ai trong tình yêu ai không mơ mộng ngu ngơ từn...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                           title artist_name  \\\n",
       "0  1073748245          Đêm Chôn Dầu Vượt Biển   Như Quỳnh   \n",
       "1  1073751978               Mùa Thu Trong Mưa  Minh Tuyết   \n",
       "2  1073835561               Rồi Ánh Trăng Tan    Lưu Bích   \n",
       "3  1073856553  Còn Thương Rau Đắng Mọc Sau Hè   Như Quỳnh   \n",
       "4  1073929630             Người Điên Biết Yêu    Như Loan   \n",
       "\n",
       "                                               lyric  label dataset  \n",
       "0  đêm nay anh gánh dầu ra biển anh chôn anh chôn...    7.0   train  \n",
       "1  chiều mưa không có em bờ đá công viên âm thầm ...    3.0   train  \n",
       "2  rồi ánh trăng cũng đang tan dần rồi ước mơ cũn...    6.0   train  \n",
       "3  nắng hạ đi mây trôi lang thang cho hạ buồn coi...    2.0   train  \n",
       "4  ai trong tình yêu ai không mơ mộng ngu ngơ từn...    7.0   train  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['lyric'], inplace=True)\n",
    "\n",
    "def cleanString(string):\n",
    "  return re.sub('\\W+',' ', string )\n",
    "df.lyric = df.lyric.apply(lambda x: cleanString(x))\n",
    "df.lyric = df.lyric.apply(lambda x: x.lower())\n",
    "\n",
    "df_train = df[df.dataset=='train']\n",
    "df_test = df[df.dataset=='test']\n",
    "print(df_train.shape)\n",
    "df_train.drop_duplicates(subset='lyric', keep='first',inplace=True)\n",
    "print(df_train.shape)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF_IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=LongMatchingTokenizer().tokenize, norm='l2')\n",
    "vectors = vectorizer.fit_transform(df_train.lyric)\n",
    "dense = vectors.todense()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=99999)\n",
    "parameters = {}\n",
    "def rmse(targets, predictions):\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tien/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    5.3s remaining:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.8s remaining:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.4s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.8s finished\n",
      "/home/tien/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.66140532]), 'std_fit_time': array([0.12973313]), 'mean_score_time': array([0.20834618]), 'std_score_time': array([0.03620178]), 'params': [{}], 'split0_test_score': array([-3.8422449]), 'split1_test_score': array([-3.72618601]), 'split2_test_score': array([-3.96938282]), 'split3_test_score': array([-4.21805642]), 'split4_test_score': array([-4.07087214]), 'split5_test_score': array([-3.88282181]), 'split6_test_score': array([-3.9904119]), 'split7_test_score': array([-3.79110401]), 'split8_test_score': array([-4.17573164]), 'split9_test_score': array([-4.02644321]), 'mean_test_score': array([-3.96877765]), 'std_test_score': array([0.15271417]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([-1.46135912]), 'split1_train_score': array([-1.45226535]), 'split2_train_score': array([-1.40358917]), 'split3_train_score': array([-1.38484069]), 'split4_train_score': array([-1.42648258]), 'split5_train_score': array([-1.31996048]), 'split6_train_score': array([-1.38905158]), 'split7_train_score': array([-1.40392133]), 'split8_train_score': array([-1.43066848]), 'split9_train_score': array([-1.43393681]), 'mean_train_score': array([-1.41060756]), 'std_train_score': array([0.03866426])}\n",
      "-3.9687776539032567\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "gs_clf = RandomizedSearchCV(nb, \n",
    "                      parameters, \n",
    "                      scoring=rmse_scorer, \n",
    "                      cv=skf,\n",
    "                      n_jobs=-1,\n",
    "                      return_train_score=True,\n",
    "                      error_score='raise',\n",
    "                      n_iter=100,\n",
    "                      verbose=10,\n",
    "                    )\n",
    "\n",
    "gs_clf.fit(dense, df_train.label)\n",
    "print(gs_clf.cv_results_)\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error valid set:-3.968\n",
    "std valid set: 0.152\n",
    "error train set:-1.41\n",
    "std train set: 0.038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tien/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  2.7min remaining:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:  2.9min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  2.9min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([80.74698358]), 'std_fit_time': array([5.69428658]), 'mean_score_time': array([8.99076247]), 'std_score_time': array([0.63681479]), 'params': [{}], 'split0_test_score': array([-2.90156741]), 'split1_test_score': array([-2.91793282]), 'split2_test_score': array([-2.89497495]), 'split3_test_score': array([-2.9731734]), 'split4_test_score': array([-2.91293237]), 'split5_test_score': array([-2.87760706]), 'split6_test_score': array([-2.93436199]), 'split7_test_score': array([-2.82274332]), 'split8_test_score': array([-2.9686052]), 'split9_test_score': array([-2.81125501]), 'mean_test_score': array([-2.90164677]), 'std_test_score': array([0.05086039]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([-2.84178944]), 'split1_train_score': array([-2.83683902]), 'split2_train_score': array([-2.83942866]), 'split3_train_score': array([-2.82750552]), 'split4_train_score': array([-2.84059723]), 'split5_train_score': array([-2.84462504]), 'split6_train_score': array([-2.83581606]), 'split7_train_score': array([-2.85169659]), 'split8_train_score': array([-2.83322684]), 'split9_train_score': array([-2.85747197]), 'mean_train_score': array([-2.84089964]), 'std_train_score': array([0.00829908])}\n",
      "-2.9016467659694802\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(gamma='scale', C=4)\n",
    "gs_clf = RandomizedSearchCV(svr, \n",
    "                      parameters, \n",
    "                      scoring=rmse_scorer, \n",
    "                      cv=skf,\n",
    "                      n_jobs=-1,\n",
    "                      return_train_score=True,\n",
    "                      error_score='raise',\n",
    "                      n_iter=100,\n",
    "                      verbose=10,\n",
    "                    )\n",
    "\n",
    "gs_clf.fit(dense, df_train.label)\n",
    "print(gs_clf.cv_results_)\n",
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error valid set:-2.901\n",
    "std valid set: 0.05\n",
    "error train set:-2.84\n",
    "std train set: 0.008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalize with artist_name and keep the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2981, 6)\n",
      "(2766, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tien/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>lyric</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073748245</td>\n",
       "      <td>Đêm Chôn Dầu Vượt Biển</td>\n",
       "      <td>NhưQuỳnh_</td>\n",
       "      <td>NhưQuỳnh_đêm nay anh gánh dầu ra biển anh chôn...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073751978</td>\n",
       "      <td>Mùa Thu Trong Mưa</td>\n",
       "      <td>MinhTuyết_</td>\n",
       "      <td>MinhTuyết_chiều mưa không có em bờ đá công viê...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073835561</td>\n",
       "      <td>Rồi Ánh Trăng Tan</td>\n",
       "      <td>LưuBích_</td>\n",
       "      <td>LưuBích_rồi ánh trăng cũng đang tan dần rồi ướ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073856553</td>\n",
       "      <td>Còn Thương Rau Đắng Mọc Sau Hè</td>\n",
       "      <td>NhưQuỳnh_</td>\n",
       "      <td>NhưQuỳnh_nắng hạ đi mây trôi lang thang cho hạ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1073929630</td>\n",
       "      <td>Người Điên Biết Yêu</td>\n",
       "      <td>NhưLoan_</td>\n",
       "      <td>NhưLoan_ai trong tình yêu ai không mơ mộng ngu...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                           title artist_name  \\\n",
       "0  1073748245          Đêm Chôn Dầu Vượt Biển   NhưQuỳnh_   \n",
       "1  1073751978               Mùa Thu Trong Mưa  MinhTuyết_   \n",
       "2  1073835561               Rồi Ánh Trăng Tan    LưuBích_   \n",
       "3  1073856553  Còn Thương Rau Đắng Mọc Sau Hè   NhưQuỳnh_   \n",
       "4  1073929630             Người Điên Biết Yêu    NhưLoan_   \n",
       "\n",
       "                                               lyric  label dataset  \n",
       "0  NhưQuỳnh_đêm nay anh gánh dầu ra biển anh chôn...    7.0   train  \n",
       "1  MinhTuyết_chiều mưa không có em bờ đá công viê...    3.0   train  \n",
       "2  LưuBích_rồi ánh trăng cũng đang tan dần rồi ướ...    6.0   train  \n",
       "3  NhưQuỳnh_nắng hạ đi mây trôi lang thang cho hạ...    2.0   train  \n",
       "4  NhưLoan_ai trong tình yêu ai không mơ mộng ngu...    7.0   train  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['lyric'], inplace=True)\n",
    "\n",
    "def cleanString(string):\n",
    "  return re.sub('\\W+',' ', string )\n",
    "df.lyric = df.lyric.apply(lambda x: cleanString(x))\n",
    "df.lyric = df.lyric.apply(lambda x: x.lower())\n",
    "\n",
    "def artist_func(string):\n",
    "  return ''.join(string.split(' '))+ \"_\"\n",
    "df['artist_name'] = df['artist_name'].apply(lambda x: artist_func(x))\n",
    "df['lyric'] = df['artist_name'] + df['lyric']\n",
    "\n",
    "df_train = df[df.dataset=='train']\n",
    "df_test = df[df.dataset=='test']\n",
    "print(df_train.shape)\n",
    "df_train.drop_duplicates(subset='lyric', keep='first',inplace=True)\n",
    "print(df_train.shape)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing vectorize (since tf_idf couldnt be run, they said that  \"The task could not be sent to the workers as it is too large for `send_bytes` SVr\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_tokenize(string):\n",
    "    m = LongMatchingTokenizer().tokenize(string.split(\"_\")[1])\n",
    "    return [string.split(\"_\")[0]+\"_\"+i for i in m]\n",
    "\n",
    "vectorizer = HashingVectorizer(tokenizer=new_tokenize, norm='l2', n_features=2**13)\n",
    "vectors = vectorizer.fit_transform(df_train.lyric)\n",
    "dense = vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tien/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  2.5min remaining:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:  2.6min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  2.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([72.9785805]), 'std_fit_time': array([5.22883305]), 'mean_score_time': array([8.11016085]), 'std_score_time': array([0.56398312]), 'params': [{}], 'split0_test_score': array([-2.97688916]), 'split1_test_score': array([-2.99255808]), 'split2_test_score': array([-2.8919988]), 'split3_test_score': array([-3.00028577]), 'split4_test_score': array([-2.88902847]), 'split5_test_score': array([-2.71726812]), 'split6_test_score': array([-2.82788564]), 'split7_test_score': array([-2.9044934]), 'split8_test_score': array([-2.95196821]), 'split9_test_score': array([-2.91689452]), 'mean_test_score': array([-2.90718464]), 'std_test_score': array([0.0811742]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([-2.64261658]), 'split1_train_score': array([-2.64103785]), 'split2_train_score': array([-2.67055401]), 'split3_train_score': array([-2.64312366]), 'split4_train_score': array([-2.65842935]), 'split5_train_score': array([-2.68891836]), 'split6_train_score': array([-2.6832127]), 'split7_train_score': array([-2.65875783]), 'split8_train_score': array([-2.65119734]), 'split9_train_score': array([-2.66005656]), 'mean_train_score': array([-2.65979042]), 'std_train_score': array([0.01585593])}\n",
      "-2.907184637796866\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(gamma='scale', C=9)\n",
    "skf = StratifiedKFold(n_splits=10, random_state=99999)\n",
    "svr_clf = RandomizedSearchCV(svr, \n",
    "                      parameters, \n",
    "                      scoring=rmse_scorer, \n",
    "                      cv=skf,\n",
    "                      n_jobs=-1,\n",
    "                      return_train_score=True,\n",
    "                      error_score='raise',\n",
    "                      n_iter=100,\n",
    "                      verbose=10,\n",
    "                    )\n",
    "\n",
    "svr_clf.fit(dense, df_train.label)\n",
    "print(svr_clf.cv_results_)\n",
    "print(svr_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error -2.907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# personalize with artist_name and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../vietnamese-stopwords.txt\", 'r') as f:\n",
    "    filecontent=f.readlines()\n",
    "stopwords = list(set([f.strip() for f in filecontent]))\n",
    "for i in range(0,len(stopwords)):\n",
    "    stopwords[i] = \"_\".join(stopwords[i].split(\" \"))\n",
    "\n",
    "def new_tokenize2(string):\n",
    "    m = LongMatchingTokenizer().tokenize(string.split(\"_\")[1])\n",
    "    m = [i for i in m if i not in stopwords]\n",
    "    return [string.split(\"_\")[0]+\"_\"+i for i in m]\n",
    "\n",
    "vectorizer = HashingVectorizer(tokenizer=new_tokenize2, norm='l2', n_features=2**13)\n",
    "vectors = vectorizer.fit_transform(df_train.lyric)\n",
    "dense = vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tien/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  2.5min remaining:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:  2.6min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  2.6min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([72.68586118]), 'std_fit_time': array([5.04923071]), 'mean_score_time': array([8.05854468]), 'std_score_time': array([0.55405814]), 'params': [{}], 'split0_test_score': array([-2.99613118]), 'split1_test_score': array([-3.00596384]), 'split2_test_score': array([-2.94200921]), 'split3_test_score': array([-2.9774999]), 'split4_test_score': array([-2.92702805]), 'split5_test_score': array([-2.78642743]), 'split6_test_score': array([-2.88110816]), 'split7_test_score': array([-2.9376594]), 'split8_test_score': array([-2.96576237]), 'split9_test_score': array([-2.95496778]), 'mean_test_score': array([-2.93766034]), 'std_test_score': array([0.06082552]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([-2.69793226]), 'split1_train_score': array([-2.69682635]), 'split2_train_score': array([-2.71381583]), 'split3_train_score': array([-2.7033087]), 'split4_train_score': array([-2.71031486]), 'split5_train_score': array([-2.73997943]), 'split6_train_score': array([-2.73101785]), 'split7_train_score': array([-2.70936291]), 'split8_train_score': array([-2.70651807]), 'split9_train_score': array([-2.71114582]), 'mean_train_score': array([-2.71202221]), 'std_train_score': array([0.01300798])}\n",
      "-2.937660339294429\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(gamma='scale', C=9)\n",
    "skf = StratifiedKFold(n_splits=10, random_state=99999)\n",
    "svr_clf = RandomizedSearchCV(svr, \n",
    "                      parameters, \n",
    "                      scoring=rmse_scorer, \n",
    "                      cv=skf,\n",
    "                      n_jobs=-1,\n",
    "                      return_train_score=True,\n",
    "                      error_score='raise',\n",
    "                      n_iter=100,\n",
    "                      verbose=10,\n",
    "                    )\n",
    "\n",
    "svr_clf.fit(dense, df_train.label)\n",
    "print(svr_clf.cv_results_)\n",
    "print(svr_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
