{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>composers_name</th>\n",
       "      <th>composers_id</th>\n",
       "      <th>release_time</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.key_edma.key</th>\n",
       "      <th>tonal.key_edma.scale</th>\n",
       "      <th>tonal.key_krumhansl.key</th>\n",
       "      <th>tonal.key_krumhansl.scale</th>\n",
       "      <th>tonal.key_temperley.key</th>\n",
       "      <th>tonal.key_temperley.scale</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>album_hash_x</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>album_hash_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1073748245</td>\n",
       "      <td>Đêm Chôn Dầu Vượt Biển</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>551</td>\n",
       "      <td>Châu Đình An</td>\n",
       "      <td>5765</td>\n",
       "      <td>2017-10-01 22:07:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>0</td>\n",
       "      <td>3c5c7e72f9112800</td>\n",
       "      <td>0</td>\n",
       "      <td>3c5c7e72f9112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1073751978</td>\n",
       "      <td>Mùa Thu Trong Mưa</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Trường Sa</td>\n",
       "      <td>100105</td>\n",
       "      <td>2017-10-01 20:58:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>1</td>\n",
       "      <td>f39df9c10843e3fc</td>\n",
       "      <td>1</td>\n",
       "      <td>f39df9c10843e3fc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          ID                   title artist_name artist_id  \\\n",
       "0      0  1073748245  Đêm Chôn Dầu Vượt Biển   Như Quỳnh       551   \n",
       "1      1  1073751978       Mùa Thu Trong Mưa  Minh Tuyết       455   \n",
       "\n",
       "  composers_name composers_id         release_time  label dataset  ...  \\\n",
       "0   Châu Đình An         5765  2017-10-01 22:07:00    7.0   train  ...   \n",
       "1      Trường Sa       100105  2017-10-01 20:58:00    3.0   train  ...   \n",
       "\n",
       "   tonal.key_edma.key tonal.key_edma.scale tonal.key_krumhansl.key  \\\n",
       "0                   G                major                       G   \n",
       "1                   C                minor                       C   \n",
       "\n",
       "  tonal.key_krumhansl.scale tonal.key_temperley.key tonal.key_temperley.scale  \\\n",
       "0                     major                       G                     major   \n",
       "1                     minor                       C                     minor   \n",
       "\n",
       "   Unnamed: 0_x      album_hash_x  Unnamed: 0_y      album_hash_y  \n",
       "0             0  3c5c7e72f9112800             0  3c5c7e72f9112800  \n",
       "1             1  f39df9c10843e3fc             1  f39df9c10843e3fc  \n",
       "\n",
       "[2 rows x 141 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "DATA_DIR = \"/home/vuthede/AI/zalo/zalo-hit-song-prediction/csv/\"\n",
    "TRAININFO = os.path.join(DATA_DIR, \"train_info.tsv\")\n",
    "TRAINRANK =  os.path.join(DATA_DIR, \"train_rank.csv\")\n",
    "TESTINFO = os.path.join(DATA_DIR, \"test_info.tsv\")\n",
    "SUBMISSION = os.path.join(DATA_DIR, \"submission.csv\")\n",
    "\n",
    "# Prepare data\n",
    "df_i = pd.read_csv(TRAININFO, delimiter='\\t',encoding='utf-8')\n",
    "df_r = pd.read_csv(TRAINRANK)\n",
    "df_i_train = df_i.merge(df_r, left_on='ID', right_on='ID')\n",
    "df_i_train[\"dataset\"] = \"train\"\n",
    "\n",
    "df_i_test = pd.read_csv(TESTINFO, delimiter='\\t',encoding='utf-8')\n",
    "df_i_test[\"label\"] = np.nan\n",
    "df_i_test[\"dataset\"] = \"test\"\n",
    "\n",
    "df = pd.concat([df_i_train, df_i_test])\n",
    "df_track_info = pd.read_csv(os.path.join(DATA_DIR, \"all_track_info.csv\"))\n",
    "df = df.merge(df_track_info, left_on='ID', right_on='ID')\n",
    "df_audio_features = pd.read_csv(os.path.join(DATA_DIR, \"all_track_audio_features.csv\"))\n",
    "df =df.merge(df_audio_features,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "df_album_hash = pd.read_csv(os.path.join(DATA_DIR, \"album_hash.csv\")) \n",
    "df =df.merge(df_album_hash,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "\n",
    "# Sort by ID\n",
    "df = df.sort_values(by=['ID'])\n",
    "df= df.reset_index()\n",
    "\n",
    "df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 0.24038838760298156 ratio is nan album\n",
      "There is 0.0017653981953707335 ratio is nan genre\n",
      "There is 0.24038838760298156 ratio is nan album_artist\n",
      "There is 0.0007846214201647705 ratio is nan track\n",
      "There is 0.6722244017261672 ratio is nan lyric\n",
      "2711 raw titles are identical between songs: 7485 unique titles\n",
      "After cleaning brackets etc. only 6202 unique titles remain, i.e. 1283 are highly similar titles \n",
      "In making albumHashandName, we filled in: 146 values Of the total albumHashAndName 171 nan\n",
      "In making albumHashAndNameAndReleaseday, we filled in the: 171 values remaining using the release second hash\n",
      "There is a statistically signficiant relationship between English-like title and rank. So adding feature: isEnglishLikeTitle\n"
     ]
    }
   ],
   "source": [
    "from format_features import format_features, add_artist_bestrank\n",
    "df = format_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_in_order = {## album is Redundant feature use: albumHashAndNameAndReleaseday\", # album name from mp3 metadata textual\n",
    "                          \"albumHashAndNameAndReleaseday\":\"category\",\n",
    "                          \"len_album_name\":\"int64\",\n",
    "                          \"isRemixAlbum\":\"category\",\n",
    "                          \"isOSTAlbum\":\"category\",\n",
    "                          \"isSingleAlbum\":\"category\",\n",
    "                          \"isBeatAlbum\":\"category\",\n",
    "                          \"isTopHitAlbum\":\"category\",\n",
    "                          \"isCoverAlbum\":\"category\",\n",
    "                          \"isEPAlbum\":\"category\",\n",
    "                          \"isLienKhucAlbum\":\"category\",\n",
    "                          \"album_name_is_title_name\":\"category\",\n",
    "                          \"artist_name\":\"category\",\n",
    "                          \"composers_name\":\"category\",\n",
    "                          \"copyright\":\"category\" ,\n",
    "                          \"artist_id_min\":\"category\",\n",
    "                          \"artist_id_max\":\"category\", \n",
    "                          \"composers_id_min\":\"category\", \n",
    "                          \"composers_id_max\":\"category\",\n",
    "                          \"genre\":\"category\", \n",
    "                          \"album_artist\":\"category\", # album artist name\n",
    "                          \"album_artist_contain_artistname\":\"category\",\n",
    "                          \"track\":\"float64\", # float between 0 and 1 representing track_num/total_tracks\n",
    "                          \"istrack11\":\"category\", # 1 if first track\n",
    "                          # \"lyric\":\"string\" # Not a trainable feature\n",
    "                          \"islyric\":\"category\",\n",
    "                          \"num_line_lyric\":\"int64\",\n",
    "                          \"no_artist\":\"int64\",\n",
    "                          \"no_composer\":\"int64\",\n",
    "                          #\"datetime\":\"datetime64\", # Not a trainable feature\n",
    "                          \"day\":\"category\",\n",
    "                          \"month\":\"category\",\n",
    "                          \"year\":\"category\",\n",
    "                          \"hour\":\"category\",\n",
    "                          \"dayofyear\":\"category\",\n",
    "                          \"weekday\":\"category\",\n",
    "                          \"isHoliday\":\"category\",\n",
    "                          \"len_of_songname\":\"int64\",\n",
    "                          \"isRemix\":\"category\",\n",
    "                          \"isOST\":\"category\",\n",
    "                          \"isBeat\":\"category\",\n",
    "                          \"isVersion\":\"category\",\n",
    "                          \"isCover\":\"category\",\n",
    "                          \"isLienKhuc\":\"category\",\n",
    "                          \"day_release\":\"int64\", # the specific day of the day across all days (> 365)  \n",
    "                          \"datetimeIs_month_end\":\"category\",\n",
    "                          \"datetimeIs_month_start\":\"category\",\n",
    "                          \"datetimeIs_quarter_end\":\"category\",\n",
    "                          \"datetimeIs_quarter_start\":\"category\",\n",
    "                          \"datetimeIs_year_end\":\"category\",\n",
    "                          \"datetimeIs_year_start\":\"category\",\n",
    "                          \"datetimeDayofweek\":\"category\",\n",
    "                          \"tonal.chords_key\":\"category\",\n",
    "                          \"tonal.chords_scale\":\"category\",\n",
    "                          'datetimeweekday_cos':\"float64\",\n",
    "                          'datetimeweekday_sin':\"float64\", \n",
    "                          'datetimeday_month_cos':\"float64\",\n",
    "                          'datetimeday_month_sin':\"float64\", \n",
    "                          'datetimemonth_year_cos':\"float64\",\n",
    "                          'datetimemonth_year_sin':\"float64\", \n",
    "                          'datetimeday_year_cos':\"float64\",\n",
    "                          'datetimeday_year_sin':\"float64\",\n",
    "                          \"length\":\"float64\", # length of the song (s?)\n",
    "                          # (title feature likely rendered redundant - use title_truncated )\"title\":\"category\",\n",
    "                          'title_truncated':\"category\",\n",
    "                          ###########################\n",
    "                          # Warning: the below features those that require \"global\" knowledge beyond that example\n",
    "                          ###########################\n",
    "                          \"numsongInAlbum\":\"category\",\n",
    "                          \"isSingleAlbum_onesong\":\"category\",\n",
    "                           #\"num_song_released_that_week\":'int64',\n",
    "                          \"num_song_release_in_final_month\":\"int64\",  \n",
    "                          \"freq_artist\":\"int64\",  # number of times the unique artist string is present in dataset\n",
    "                          \"freq_artist_min\":\"int64\", # number of times the first listed artist is present in dataset\n",
    "                          \"num_album_per_min_artist\":\"int64\",\n",
    "                          \"num_album_per_min_composer\":\"int64\",\n",
    "                          \"freq_composer_min\":\"int64\",   \n",
    "                          \"isEnglishLikeTitle\":\"category\" # has some words with no special charachters - in practice selects short and weird titles\n",
    "                          }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_artist_bestrank(df,all_features_in_order):\n",
    "    from datetime import datetime\n",
    "    import re\n",
    "\n",
    "    def split_id(s):\n",
    "        return re.split(',|\\.',s)\n",
    "\n",
    "    m = df.artist_id.unique()\n",
    "    idx_lst = []\n",
    "    for idx in m:\n",
    "        ps = split_id(idx)\n",
    "        for i in ps:\n",
    "            idx_lst.append(i)\n",
    "\n",
    "    id_lst = list(set(idx_lst))\n",
    "\n",
    "    def condition(df, artist_id):\n",
    "        r = df.artist_id.apply(lambda x: artist_id in split_id(x))\n",
    "        return r\n",
    "\n",
    "    df_train = df[df.dataset==\"train\"]\n",
    "    data= [df_train[condition(df_train, artist_id)].label.agg([\"mean\",\"std\",\"count\"]) for artist_id in id_lst]\n",
    "    new_df = pd.DataFrame(data=data)\n",
    "    new_df[\"artist_id\"] =  id_lst\n",
    "\n",
    "    new_df.dropna(inplace=True)\n",
    "    new_df.set_index('artist_id', inplace=True)\n",
    "    art_dict = new_df.to_dict()\n",
    "\n",
    "    def best_count_id(values):\n",
    "        ids = split_id(values)\n",
    "        temp_mean = 0\n",
    "        temp_id = str(min([int(a) for a in ids]))\n",
    "        for id in ids:\n",
    "            try:\n",
    "                if art_dict['count'][id] > temp_mean:\n",
    "                    temp_mean = art_dict['count'][id]\n",
    "                    temp_id = id\n",
    "            except:\n",
    "                temp_mean = temp_mean\n",
    "                temp_id = temp_id\n",
    "        return temp_id\n",
    "\n",
    "    df['artist_bestcount'] = df['artist_id'].apply(best_count_id)\n",
    "\n",
    "    def best_mean_id(values):\n",
    "        ids = split_id(values)\n",
    "        temp_mean = 10\n",
    "        temp_id = str(min([int(a) for a in ids]))\n",
    "        for id in ids:\n",
    "            try:\n",
    "                if art_dict['mean'][id] < temp_mean:\n",
    "                    temp_mean = art_dict['mean'][id]\n",
    "                    temp_id = id\n",
    "            except:\n",
    "                temp_mean = temp_mean\n",
    "                temp_id = temp_id\n",
    "        return temp_id\n",
    "\n",
    "    df['artist_bestmeanrank'] = df['artist_id'].apply(best_mean_id)\n",
    "\n",
    "    def best_std_id(values):\n",
    "        ids = split_id(values)\n",
    "        temp_std = 10\n",
    "        temp_id = str(min([int(a) for a in ids]))\n",
    "        for id in ids:\n",
    "            try:\n",
    "                if art_dict['std'][id] < temp_std:\n",
    "                    temp_std = art_dict['std'][id]\n",
    "                    temp_id = id\n",
    "            except:\n",
    "                temp_std = temp_std\n",
    "                temp_id = temp_id\n",
    "        return temp_id\n",
    "\n",
    "    df['artist_beststdrank'] = df['artist_id'].apply(best_std_id)\n",
    "\n",
    "    df['artist_mean_id'] = df['artist_mean_id']\n",
    "    df['artist_std_id'] = df['artist_std_id']\n",
    "    df['artist_bestcount'] = df['artist_bestcount']\n",
    "\n",
    "def add_raw_audio_features(df, all_features_in_order):\n",
    "    not_included_columns = set(df.columns) - set([i for i in all_features_in_order.keys()]) - set([\"tonal.chords_key\", \"tonal.chords_scale\"])\n",
    "    audio_feature_names = sorted([i for i in not_included_columns if i.split(\".\")[0] == 'tonal'\n",
    "            or  i.split(\".\")[0] == 'rhythm'\n",
    "            or  i.split(\".\")[0]=='lowlevel'])\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    audio_feature_names_dict = {name:\"float64\" for name in audio_feature_names}\n",
    "    audio_feature_names_dict[\"tonal.chords_key\"] = \"category\"\n",
    "    audio_feature_names_dict[\"tonal.chords_scale\"] = \"category\"\n",
    "    audio_feature_names_dict[\"tonal.key_edma.key\"] = \"category\"\n",
    "    audio_feature_names_dict[\"tonal.key_edma.scale\"] = \"category\"\n",
    "    audio_feature_names_dict[\"tonal.key_krumhansl.key\"] = \"category\"\n",
    "    audio_feature_names_dict[\"tonal.key_krumhansl.scale\"] = \"category\"\n",
    "    audio_feature_names_dict[\"tonal.key_temperley.key\"] = \"category\"\n",
    "    audio_feature_names_dict[\"tonal.key_temperley.scale\"] = \"category\"\n",
    "    all_features_in_order.update(audio_feature_names_dict)\n",
    "    return all_features_in_order\n",
    "\n",
    "all_features_in_order = add_raw_audio_features(df, all_features_in_order)\n",
    "all_features_in_order_list = list(all_features_in_order.keys())\n",
    "for feat_name, feat_type in all_features_in_order.items():\n",
    "    try:\n",
    "        df[feat_name] = df[feat_name].astype(feat_type)\n",
    "    except ValueError:\n",
    "        print(feat_name, feat_type)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from format_features import baysianEncodeFeature\n",
    "\n",
    "\n",
    "best_chosen_features = \n",
    "[\"albumHashAndNameAndReleaseday_enc\", \"istrack11\", \"no_artist\", \"no_composer\",\"freq_artist\", \"freq_composer\",\n",
    " \"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "\"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "\"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "\"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "\"isBeatAlbum\", \"isCoverAlbum\", \"artist_name_cat\",\"composers_name_cat\",\"copyright_cat\" ,\n",
    "# \"artist_id_min_cat\", \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\", \n",
    "\"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\"isHoliday\",\n",
    "\"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "\"numsongInAlbum\",\"isSingleAlbum_onesong\",\n",
    " \"artist_mean_id\", \"artist_std_id\" ,\"artist_count_id\",\"title_cat\",\"num_same_title\"]\n",
    "\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "categorical_col_names = df[all_features_in_order_list].select_dtypes(include=['category']).columns\n",
    "for colname in categorical_col_names:\n",
    "    df[colname] = df[colname].cat.codes\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chosen_features = bens_chosen_features\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "df_test = df[df.dataset==\"test\"]\n",
    "\n",
    "param = {\n",
    "    'bagging_freq': 20,          \n",
    "    'bagging_fraction': 0.95,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             'feature_fraction': 0.1,     'learning_rate': 0.001,\n",
    "    'max_depth': -1,             'metric':'root_mean_squared_error', 'min_data_in_leaf': 100, # cjha   \n",
    "       'num_leaves': 20,            \n",
    "    'num_threads': 4,              'tree_learner': 'serial',   'objective': 'regression',\n",
    "    'reg_alpha': 0.1002650970728192, 'reg_lambda': 0.1003427518866501,'verbosity': 1,\n",
    "    \"seed\": 99999\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=99999)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "labels= df_train.label\n",
    "# fig, axes = plt.subplots(5, 1, figsize=(10, 10*5))\n",
    "# axes = axes.flat\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train.label.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "    df_train = baysianEncodeFeature(df_train, trn_idx, 'albumHashAndNameAndReleaseday', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "    df_train = baysianEncodeFeature(df_train, trn_idx, 'artist_id_min', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "    df_train = baysianEncodeFeature(df_train, trn_idx, 'title_truncated', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "\n",
    "    train_df_fold = df_train.iloc[trn_idx][chosen_features]\n",
    "    val_df_fold = df_train.iloc[val_idx][chosen_features]\n",
    "    trn_data = lgb.Dataset(train_df_fold, label=labels.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(val_df_fold, label=labels.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 20000)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][chosen_features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(df_test[chosen_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "# training's rmse: 0.428706\tvalid_1's rmse: 1.57874\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"RMSE: {:<8.5f}\".format(sqrt(mean_squared_error(df_train.label, oof))))\n",
    "sub = pd.DataFrame({\"ID\": df_test.ID.values})\n",
    "sub[\"label\"] = predictions\n",
    "sub.to_csv(\"submission_lightgbm.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "lgb.plot_importance(clf, max_num_features=20,importance_type='gain')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
