{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "TRAININFO = \"/data/HitSongPrediction/train_info.tsv\"\n",
    "TRAINRANK =  \"/data/HitSongPrediction/train_rank.csv\"\n",
    "TESTINFO = \"/data/HitSongPrediction/test_info.tsv\"\n",
    "SUBMISSION = \"/data/HitSongPrediction/submission.csv\"\n",
    "\n",
    "# Prepare data\n",
    "df_i = pd.read_csv(TRAININFO, delimiter='\\t',encoding='utf-8')\n",
    "df_r = pd.read_csv(TRAINRANK)\n",
    "df_i_train = df_i.merge(df_r, left_on='ID', right_on='ID')\n",
    "df_i_train[\"dataset\"] = \"train\"\n",
    "\n",
    "df_i_test = pd.read_csv(TESTINFO, delimiter='\\t',encoding='utf-8')\n",
    "df_i_test[\"label\"] = np.nan\n",
    "df_i_test[\"dataset\"] = \"test\"\n",
    "\n",
    "df = pd.concat([df_i_train, df_i_test])\n",
    "df_track_info = pd.read_csv(\"../../csv/all_track_info.csv\")\n",
    "df = df.merge(df_track_info, left_on='ID', right_on='ID')\n",
    "df_audio_features = pd.read_csv(\"../../csv/all_track_audio_features.csv\")\n",
    "df =df.merge(df_audio_features,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "\n",
    "df_album_hash = pd.read_csv(\"../../csv/album_hash.csv\") \n",
    "df =df.merge(df_album_hash,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "\n",
    "#Drop duplicate song\n",
    "def remove_duplicate_songs_with_low_ranks(df):\n",
    "    duplicateRowsDF = df[df.duplicated([\"title\", \"album\", \"artist_name\"], False)]\n",
    "    duplicateRowsDF = duplicateRowsDF[~duplicateRowsDF.label.isnull()]\n",
    "    all_index = duplicateRowsDF.index\n",
    "\n",
    "    duplicateRowsDF= duplicateRowsDF.sort_values(by=['label'])\n",
    "    duplicateRowsDF = duplicateRowsDF.drop_duplicates([\"title\", \"album\", \"artist_name\"],keep=\"first\")\n",
    "    keep_index = duplicateRowsDF.index\n",
    "\n",
    "    remove_index = list(set(all_index) - set(keep_index))\n",
    "    df = df.drop(remove_index)\n",
    "    return df\n",
    "df = remove_duplicate_songs_with_low_ranks(df)\n",
    "\n",
    "# Sort by ID\n",
    "df = df.sort_values(by=['ID'])\n",
    "df= df.reset_index()\n",
    "\n",
    "print(len(df))\n",
    "# df.head(5683)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10000)\n",
    "df[\"num_len_same\"] = df.groupby([\"length\",\"artist_id\"])[\"ID\"].transform(\"count\")\n",
    "df1 = df[df.num_len_same > 1]\n",
    "\n",
    "df1 = df1.sort_index(by=\"length\")\n",
    "df1[[\"ID\",\"title\", \"album\", \"album_artist\", \"artist_name\",\"genre\", \"composers_name\", \"track\",\"release_time\",\"length\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_truncated'] = df['title'].str.split('(', expand=True).loc[:, 0].str.rstrip().str.rstrip('!').str.rstrip(\n",
    "        '?')\n",
    "\n",
    "len(df.title_truncated.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_bracket(tit):\n",
    "    return tit.split('(')[0]\n",
    "\n",
    "df['no_bracket_title'] = df.title.apply(lambda x: no_bracket(x))\n",
    "len(df.no_bracket_title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRowsDF = df[df.duplicated([\"title\", \"album\", \"artist_name\"], False)]\n",
    "duplicateRowsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.length==0][[\"title\", \"album\", \"album_artist\", \"artist_name\",\"genre\", \"composers_name\", \"track\",\"release_time\",\"length\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Fill nan album\n",
    "print(\"There is {} ratio is nan album\".format(len(df[df[\"album\"].isnull()])/len(df)))\n",
    "print(\"There is {} ratio is nan album\".format(len(df[df[\"album\"].isnull()])/len(df)))\n",
    "\n",
    "df[\"album_right\"] = df.release_time.astype(\"category\").cat.codes\n",
    "df[\"albumHashAndName\"] = df[\"album_hash\"].fillna(df['album'])\n",
    "df[\"albumHashAndNameAndReleaseday\"] = df[\"albumHashAndName\"].fillna(df['album_right']).astype(\"category\").cat.codes\n",
    "assert df['albumHashAndNameAndReleaseday'].isnull().sum() == 0\n",
    "\n",
    "df[\"album_tmp\"]  = df[\"album\"].copy()\n",
    "\n",
    "df[\"album\"]  = df[\"album\"].fillna(\"\")\n",
    "df[\"len_album_name\"] = df[\"album\"].apply(lambda x: len(x.split(\" \")))\n",
    "df[\"isRemixAlbum\"] = [ 1 if \"Remix\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isRemixAlbum\"] = df[\"isRemixAlbum\"].astype(bool)\n",
    "\n",
    "df[\"isOSTAlbum\"] = [ 1 if \"OST\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isOSTAlbum\"] = df[\"isOSTAlbum\"].astype(bool)\n",
    "\n",
    "\n",
    "df[\"isSingleAlbum\"] = [ 1 if \"Single\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isSingleAlbum\"] = df[\"isSingleAlbum\"].astype(bool)\n",
    "\n",
    "df[\"isBeatAlbum\"] = [ 1 if \"Beat\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isBeatAlbum\"] = df[\"isBeatAlbum\"].astype(bool)\n",
    "\n",
    "df[\"isTopHitAlbum\"] = [ 1 if \"Top Hits\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isTopHitAlbum\"] = df[\"isTopHitAlbum\"].astype(bool)\n",
    "\n",
    "\n",
    "df[\"isCoverAlbum\"] = [ 1 if \"Cover\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isCoverAlbum\"] = df[\"isCoverAlbum\"].astype(bool)\n",
    "\n",
    "\n",
    "df[\"isEPAlbum\"] = [ 1 if \"EP\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isEPAlbum\"] = df[\"isEPAlbum\"].astype(bool)\n",
    "\n",
    "\n",
    "df[\"isLienKhucAlbum\"] = [ 1 if \"Liên Khúc\" in t else 0 for t in df[\"album\"]]\n",
    "df[\"isLienKhucAlbum\"] = df[\"isLienKhucAlbum\"].astype(bool)\n",
    "\n",
    "\n",
    "def no_bracket(tit):\n",
    "    return tit.split('(')[0]\n",
    "\n",
    "df['no_bracket_title'] = df.title.apply(lambda x: no_bracket(x))\n",
    "df[\"num_same_title_no_bracket\"] = df.groupby(\"no_bracket_title\")[\"no_bracket_title\"].transform(\"count\")\n",
    "df['no_bracket_title_cat'] = df['no_bracket_title'].astype('category').cat.codes\n",
    "\n",
    "\n",
    "df['title_truncated'] = df['title'].str.split('(', expand=True).loc[:, 0].str.rstrip().str.rstrip('!').str.rstrip(\n",
    "        '?').astype('category').cat.codes\n",
    "df[\"isEDM\"] = [ 1 if \"EDM\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isEDM\"] = df[\"isEDM\"].astype(bool)\n",
    "\n",
    "df[\"isDJ\"] = [ 1 if \"DJ\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isDJ\"] = df[\"isDJ\"].astype(bool)\n",
    "\n",
    "df[\"isMix\"] = [ 1 if \"Mix\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isMix\"] = df[\"isMix\"].astype(bool)\n",
    "\n",
    "df[\"isLive\"] = [ 1 if \"Live\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isLive\"] = df[\"isLive\"].astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "df[\"num_same_title\"] = df.groupby(\"title\")[\"title\"].transform(\"count\")\n",
    "df[\"title_cat\"] = df[\"title\"].astype('category').cat.codes\n",
    "df[\"album_name_is_title_name\"]= [1 if r.title in r.album  else 0 for i,r in df.iterrows() ]\n",
    "df[\"album\"] = df[\"album\"].astype('category')\n",
    "df[\"album\"] =  df[\"album\"].cat.codes\n",
    "\n",
    "df[\"artist_name_cat\"] = df[\"artist_name\"].astype('category')\n",
    "df[\"artist_name_cat\"] =  df[\"artist_name_cat\"].cat.codes\n",
    "df[\"composers_name_cat\"] = df[\"composers_name\"].astype('category')\n",
    "df[\"composers_name_cat\"] =  df[\"composers_name_cat\"].cat.codes\n",
    "df[\"copyright_cat\"] = df[\"copyright\"].astype('category')\n",
    "df[\"copyright_cat\"] =  df[\"copyright_cat\"].cat.codes\n",
    "\n",
    "import re\n",
    "def get_min_artist_id(s):\n",
    "    ps = re.split(',|\\.',s)\n",
    "    ps = [int(p) for p in ps]\n",
    "    return np.min(ps)\n",
    "\n",
    "def get_max_artist_id(s):\n",
    "    ps = re.split(',|\\.',s)\n",
    "    ps = [int(p) for p in ps]\n",
    "    return np.max(ps)\n",
    "\n",
    "df[\"artist_id_min\"]=  df[\"artist_id\"].apply(lambda x: get_min_artist_id(x))\n",
    "df[\"artist_id_min_cat\"] = df[\"artist_id_min\"].astype('category')\n",
    "df[\"artist_id_min_cat\"] =  df[\"artist_id_min_cat\"].cat.codes\n",
    "\n",
    "df[\"composers_id_min\"]=  df[\"composers_id\"].apply(lambda x: get_min_artist_id(x))\n",
    "df[\"composers_id_min_cat\"] = df[\"composers_id_min\"].astype('category')\n",
    "df[\"composers_id_min_cat\"] =  df[\"composers_id_min_cat\"].cat.codes\n",
    "\n",
    "df[\"artist_id_max\"]=  df[\"artist_id\"].apply(lambda x: get_max_artist_id(x))\n",
    "df[\"artist_id_max_cat\"] = df[\"artist_id_max\"].astype('category')\n",
    "df[\"artist_id_max_cat\"] =  df[\"artist_id_max_cat\"].cat.codes\n",
    "\n",
    "df[\"composers_id_max\"]=  df[\"composers_id\"].apply(lambda x: get_max_artist_id(x))\n",
    "df[\"composers_id_max_cat\"] = df[\"composers_id_max\"].astype('category')\n",
    "df[\"composers_id_max_cat\"] =  df[\"composers_id_max_cat\"].cat.codes\n",
    "\n",
    "#New feature\n",
    "# df[\"group_album_artist_id_min_cat\"] = df.groupby([\"album\",\"artist_id_min_cat\"]).ngroup()\n",
    "# df[\"group_album_artist_id_min_cat\"] = df[\"group_album_artist_id_min_cat\"].astype(\"category\").cat.codes\n",
    "# df[\"group_album_artist_id_max_cat\"] = df.groupby([\"album\",\"artist_id_max_cat\"]).ngroup()\n",
    "# df[\"group_album_artist_id_max_cat\"] = df[\"group_album_artist_id_max_cat\"].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "# Fill genre\n",
    "print(\"There is {} ratio is nan genre\".format(len(df[df[\"genre\"].isnull()])/len(df)))\n",
    "df[\"genre\"]  = df[\"genre\"].fillna(\"No genre\")\n",
    "df[\"genre\"] = df[\"genre\"].astype('category')\n",
    "df[\"genre\"] =  df[\"genre\"].cat.codes\n",
    "\n",
    "# Fill album_artist\n",
    "print(\"There is {} ratio is nan album_artist\".format(len(df[df[\"album_artist\"].isnull()])/len(df)))\n",
    "df[\"album_artist\"]  = df[\"album_artist\"].fillna(\"No album_artist\")\n",
    "df[\"album_artist_contain_artistname\"]= [1 if r.album_artist in r.artist_name  else 0 for i,r in df.iterrows() ]\n",
    "df[\"album_artist\"] = df[\"album_artist\"].astype('category')\n",
    "df[\"album_artist\"] =  df[\"album_artist\"].cat.codes\n",
    "\n",
    "# Fill track\n",
    "print(\"There is {} ratio is nan track\".format(len(df[df[\"track\"].isnull()])/len(df)))\n",
    "df[\"track_tmp\"]  = df[\"track\"].copy()\n",
    "df[\"track\"]  = df[\"track\"].fillna(\"(1, 1)\")\n",
    "df[\"istrack11\"] = df[\"track\"] == \"(1, 1)\"\n",
    "def tracknum_to_value(track_num):\n",
    "    try:\n",
    "        \n",
    "        track_num = make_tuple(track_num)\n",
    "        if track_num[0] is not None:\n",
    "            return float(track_num[0]) / float(track_num[1])\n",
    "        else:\n",
    "            return 1.0\n",
    "    except:\n",
    "        return 1.0\n",
    "\n",
    "df[\"track\"] = df[\"track\"].apply(lambda t: tracknum_to_value(t))\n",
    "\n",
    "\n",
    "# Fill lyric\n",
    "print(\"There is {} ratio is nan lyric\".format(len(df[df[\"lyric\"].isnull()])/len(df)))\n",
    "df[\"lyric\"]  = df[\"lyric\"].fillna(\"\")\n",
    "df[\"islyric\"] = df[\"lyric\"].apply(lambda x:  True if len(x)  else False)\n",
    "df[\"num_line_lyric\"] = df[\"lyric\"].apply(lambda x : len(x.split(\"\\r\")))\n",
    "\n",
    "\n",
    "#--------------------------------------------------------\n",
    "from dateutil import relativedelta\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ast import literal_eval as make_tuple\n",
    "df['no_artist'] = df.artist_name.apply(lambda x: len(x.split(\",\")))\n",
    "df['no_composer'] = df.composers_name.apply(lambda x: len(x.split(\",\")))\n",
    "df[\"freq_artist\"] = df.groupby('artist_id')['artist_id'].transform('count').astype('float')\n",
    "df[\"freq_composer\"] = df.groupby('composers_id')['composers_id'].transform('count').astype('float')\n",
    "df[\"freq_artist_min\"] = df.groupby('artist_id_min_cat')['artist_id_min_cat'].transform('count').astype('float')\n",
    "df[\"freq_composer_min\"] = df.groupby('composers_id_min_cat')['composers_id_min_cat'].transform('count').astype('float')\n",
    "\n",
    "df[\"num_album_per_min_artist\"] = df.groupby(['artist_id_min_cat','albumHashAndNameAndReleaseday'])['albumHashAndNameAndReleaseday'].transform('count').astype('float')\n",
    "df[\"num_album_per_min_composer\"] = df.groupby(['composers_id_min','albumHashAndNameAndReleaseday'])['albumHashAndNameAndReleaseday'].transform('count').astype('float')\n",
    "\n",
    "\n",
    "df[\"datetime\"] = pd.to_datetime(df.release_time)\n",
    "df[\"year\"] = df[\"datetime\"].dt.year\n",
    "df[\"month\"] = df[\"datetime\"].dt.month\n",
    "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "df[\"day\"] = df[\"datetime\"].dt.day\n",
    "df[\"dayofyear\"] = df[\"datetime\"].dt.dayofyear\n",
    "df[\"weekday\"] = df[\"datetime\"].dt.weekday\n",
    "from datetime import date \n",
    "import holidays \n",
    "\n",
    "in_holidays = holidays.HolidayBase() \n",
    "for i in range(26,32):\n",
    "    in_holidays.append(str(i)+'-01-2017')\n",
    "in_holidays.append('01-02-2017')\n",
    "for i in range(14,21):\n",
    "    in_holidays.append(str(i)+'-02-2018')\n",
    "in_holidays.append('30-04-2017')\n",
    "in_holidays.append('30-04-2018')\n",
    "in_holidays.append('01-01-2017')\n",
    "in_holidays.append('01-01-2018')\n",
    "in_holidays.append('14-02-2017')\n",
    "in_holidays.append('14-02-2018')\n",
    "in_holidays.append('08-03-2017')\n",
    "in_holidays.append('08-03-2018')\n",
    "in_holidays.append('01-05-2017')\n",
    "in_holidays.append('01-05-2018')\n",
    "in_holidays.append('06-04-2017')\n",
    "in_holidays.append('25-04-2018')\n",
    "in_holidays.append('01-06-2017')\n",
    "in_holidays.append('01-06-2018')\n",
    "in_holidays.append('04-10-2017')\n",
    "in_holidays.append('24-09-2018')\n",
    "in_holidays.append('20-10-2017')\n",
    "in_holidays.append('20-10-2018')\n",
    "in_holidays.append('20-11-2017')\n",
    "in_holidays.append('20-11-2018')\n",
    "in_holidays.append('24-12-2017')\n",
    "in_holidays.append('24-12-2018')\n",
    "df['isHoliday'] = df.release_time.apply(lambda x: x in in_holidays)\n",
    "\n",
    "\n",
    "\n",
    "df[\"len_of_songname\"] = df[\"title\"].apply(lambda x: len(x.split(\" \")))\n",
    "df[\"isRemix\"] = [ 1 if \"Remix\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isRemix\"] = df[\"isRemix\"].astype(bool)\n",
    "\n",
    "df[\"isOST\"] = [ 1 if \"OST\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isOST\"] = df[\"isOST\"].astype(bool)\n",
    "\n",
    "df[\"isBeat\"] = [ 1 if \"Beat\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isBeat\"] = df[\"isBeat\"].astype(bool)\n",
    "\n",
    "df[\"isVersion\"] = [ 1 if \"Version\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isVersion\"] = df[\"isVersion\"].astype(bool)\n",
    "\n",
    "df[\"isCover\"] = [ 1 if \"Cover\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isCover\"] = df[\"isCover\"].astype(bool)\n",
    "\n",
    "\n",
    "df[\"isLienKhuc\"] = [ 1 if \"Liên Khúc\" in t else 0 for t in df[\"title\"]]\n",
    "df[\"isLienKhuc\"] = df[\"isLienKhuc\"].astype(bool)\n",
    "\n",
    "\n",
    "\n",
    "def find_num_song_release_in_final_month(df, day):\n",
    "    month5th = day + relativedelta.relativedelta(months=5)\n",
    "    month6th = day + relativedelta.relativedelta(months=6)  \n",
    "    return len(df.datetime[(df.datetime >= month5th)&(df.datetime<=month6th)])\n",
    "\n",
    "\n",
    "\n",
    "df[\"num_song_release_in_final_month\"] = df.datetime.apply(lambda d:find_num_song_release_in_final_month(df ,d))\n",
    "\n",
    "#It seems like all songs on albums release at the same time, so groupby by release_time will create album \n",
    "\n",
    "df[\"day_release\"] = df.groupby([\"year\",\"dayofyear\"]).ngroup().astype(\"category\").cat.codes\n",
    "df[\"numsongInAlbum\"] = df.groupby(\"albumHashAndNameAndReleaseday\")[\"album_right\"].transform(\"count\")\n",
    "df[\"isSingleAlbum_onesong\"]= df[\"isSingleAlbum\"] & (df[\"numsongInAlbum\"]==1)\n",
    "\n",
    "# Remove len =0\n",
    "df = df[(df.length>0) | (df.num_same_title==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_song_that_have_abnormal_rank_in_album(df):\n",
    "    df[\"m\"] = df.groupby(\"albumHashAndNameAndReleaseday\")[\"label\"].transform(\"mean\")\n",
    "    df[\"std\"] = df.groupby(\"albumHashAndNameAndReleaseday\")[\"label\"].transform(\"std\")\n",
    "    df[\"count\"] = df.groupby(\"albumHashAndNameAndReleaseday\")[\"label\"].transform(\"count\")\n",
    "\n",
    "#     pd.set_option('display.max_rows', 100957)\n",
    "\n",
    "    df = df.sort_index(by=\"albumHashAndNameAndReleaseday\")\n",
    "    df[df.dataset==\"train\"][[\"albumHashAndNameAndReleaseday\",\"label\",\"m\",\"std\", \"count\"]]\n",
    "\n",
    "    condition = (df[\"count\"] >=10) & (np.abs(df.label - df.m) > 1.5*df[\"std\"])\n",
    "    print(\"len df:\", len(df))\n",
    "    df1 = df[~condition]\n",
    "    print(\"len df:\", len(df1))\n",
    "    df = df1.copy()\n",
    "    df = df.sort_values(by=['ID'])\n",
    "    df= df.reset_index()\n",
    "    return df\n",
    "df= remove_song_that_have_abnormal_rank_in_album(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100957)\n",
    "df = df.sort_values(by=['albumHashAndNameAndReleaseday'])\n",
    "print(len(df))\n",
    "df[[\"ID\",\"title\", \"album_tmp\", \"album_hash\", \"albumHashAndNameAndReleaseday\",\"artist_name\", \"track_tmp\",\"release_time\",\"length\",\"label\"]].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def split_id(s):\n",
    "    return re.split(',|\\.',s)\n",
    "\n",
    "m = df.artist_id.unique()\n",
    "idx_lst = []\n",
    "for idx in m:\n",
    "    ps = split_id(idx)\n",
    "    for i in ps:\n",
    "        idx_lst.append(i)\n",
    "        \n",
    "id_lst = list(set(idx_lst))\n",
    "\n",
    "def condition(df, artist_id):\n",
    "    r = df.artist_id.apply(lambda x: artist_id in split_id(x))\n",
    "    return r\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "data= [df_train[condition(df_train, artist_id)].label.agg([\"mean\",\"std\",\"count\"]) for artist_id in id_lst]\n",
    "new_df = pd.DataFrame(data=data)\n",
    "new_df[\"artist_id\"] =  id_lst\n",
    "\n",
    "new_df.dropna(inplace=True)\n",
    "new_df.set_index('artist_id', inplace=True)\n",
    "art_dict = new_df.to_dict()\n",
    "\n",
    "def best_count_id(values):\n",
    "    ids = split_id(values)\n",
    "    temp_mean = 0\n",
    "    temp_id = str(min([int(a) for a in ids]))\n",
    "    for id in ids:\n",
    "        try:\n",
    "            if art_dict['count'][id] > temp_mean:\n",
    "                temp_mean = art_dict['count'][id]\n",
    "                temp_id = id\n",
    "        except:\n",
    "            temp_mean = temp_mean\n",
    "            temp_id = temp_id\n",
    "    return temp_id\n",
    "    \n",
    "df['artist_count_id'] = df['artist_id'].apply(best_count_id)\n",
    "\n",
    "def best_mean_id(values):\n",
    "    ids = split_id(values)\n",
    "    temp_mean = 10\n",
    "    temp_id = str(min([int(a) for a in ids]))\n",
    "    for id in ids:\n",
    "        try:\n",
    "            if art_dict['mean'][id] < temp_mean:\n",
    "                temp_mean = art_dict['mean'][id]\n",
    "                temp_id = id\n",
    "        except:\n",
    "            temp_mean = temp_mean\n",
    "            temp_id = temp_id\n",
    "    return temp_id\n",
    "\n",
    "df['artist_mean_id'] = df['artist_id'].apply(best_mean_id)\n",
    "\n",
    "def best_std_id(values):\n",
    "    ids = split_id(values)\n",
    "    temp_std = 10\n",
    "    temp_id = str(min([int(a) for a in ids]))\n",
    "    for id in ids:\n",
    "        try:\n",
    "            if art_dict['std'][id] < temp_std:\n",
    "                temp_std = art_dict['std'][id]\n",
    "                temp_id = id\n",
    "        except:\n",
    "            temp_std = temp_std\n",
    "            temp_id = temp_id\n",
    "    return temp_id\n",
    "\n",
    "df['artist_std_id'] = df['artist_id'].apply(best_std_id)\n",
    "\n",
    "df['artist_mean_id'] = df['artist_mean_id'].astype(\"category\")\n",
    "df['artist_std_id'] = df['artist_std_id'].astype(\"category\")\n",
    "df['artist_count_id'] = df['artist_count_id'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def create_album_score_lookup_table(df):\n",
    "    data = df.groupby('albumHashAndNameAndReleaseday').label.agg([\"mean\",\"std\",\"count\"])\n",
    "    return data\n",
    "\n",
    "def create_artist_score_lookup_table(df):\n",
    "    def split_id(s):\n",
    "        return re.split(',|\\.',s)\n",
    "    \n",
    "    def mask_row_contain_artist_id(df, artist_id):\n",
    "        r = df.artist_id.apply(lambda x: artist_id in split_id(x))\n",
    "        return r\n",
    "    \n",
    "    # Get all artist ids\n",
    "    artist_group = df.artist_id.unique()\n",
    "    artist_ids = reduce(lambda l,e: l+split_id(e), artist_group, [])\n",
    "    artist_ids = list(set(artist_ids))\n",
    "    # Get data\n",
    "    data= [df[mask_row_contain_artist_id(df, artist_id)].label.agg([\"mean\",\"std\",\"count\", \"median\"]) \n",
    "                                                        for artist_id in artist_ids]\n",
    "    new_df = pd.DataFrame(data=data)\n",
    "    new_df[\"artist_id\"] =  artist_ids\n",
    "    return new_df.set_index(\"artist_id\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field_by_key(table, k, field=\"mean\"):\n",
    "    if k in table.index:\n",
    "        return table.loc[k][field]\n",
    "    return np.nan\n",
    "\n",
    "def get_value_by_key(table, k):\n",
    "    if k in table.index:\n",
    "        return table.loc[k], False\n",
    "    return np.nan, True\n",
    "\n",
    "def assign_value(album_table, artist_table, r):\n",
    "    d1,isnul1 = get_value_by_key(album_table, r.albumHashAndNameAndReleaseday)\n",
    "    d2,isnul2 = get_value_by_key(artist_table, r.artist_id_min_cat)\n",
    "#     print(type(d2),isnul2)\n",
    "    if isnul1 and isnul2:\n",
    "        return np.nan\n",
    "    elif isnul1 and d2[\"std\"] <2:\n",
    "        return d2[\"mean\"]\n",
    "    elif isnul2 and d1[\"std\"] <2:\n",
    "        return d1[\"mean\"]\n",
    "    \n",
    "    elif not isnul1 and d1[\"std\"] <2 and not isnul2 and d2[\"std\"] < 2:\n",
    "        return d1[\"mean\"] \n",
    "    \n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "def assign_value_album(album_table, r):\n",
    "    d1,isnul1 = get_value_by_key(album_table, r.album_right)\n",
    "    \n",
    "    if not isnul1 and d1[\"std\"] <2:\n",
    "        return d1[\"mean\"]\n",
    "    \n",
    "    return np.nan\n",
    "    \n",
    "def assign_value_artist(artist_table, r):\n",
    "    d1,isnul1 = get_value_by_key(artist_table, r.artist_id_min_cat)\n",
    "    \n",
    "    if not isnul1 and d1[\"std\"] <2:\n",
    "        return d1[\"mean\"]\n",
    "    \n",
    "    return np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.artist_mean_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xam\n",
    "\n",
    "encoder = xam.feature_extraction.BayesianTargetEncoder(\n",
    "    columns=['album_right', 'artist_mean_id',\"artist_id_min_cat\",\n",
    "             \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\"],\n",
    "    prior_weight=10000,\n",
    "    suffix='_encode')\n",
    "\n",
    "# df_train = df[df.dataset==\"train\"]\n",
    "\n",
    "target_encode = encoder.fit_transform(df[['album_right', 'artist_mean_id',\"artist_id_min_cat\",\n",
    "             \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\"]], df.label )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baysianEncodeFeature(df_train, trn_idx, featurename, prior_weight, fillmissing, suffix='_baysencoded'):\n",
    "    '''Returns new df '''\n",
    "    import xam\n",
    "\n",
    "    encoder = xam.feature_extraction.BayesianTargetEncoder(\n",
    "        columns=[featurename, ],\n",
    "        prior_weight=prior_weight,\n",
    "        suffix=suffix)\n",
    "\n",
    "    train_df_fold = df_train.iloc[trn_idx]\n",
    "\n",
    "    encoder.fit(train_df_fold[[featurename]], train_df_fold.label)\n",
    "\n",
    "    _resulting_df = encoder.transform(df_train[[featurename]], df_train.label)\n",
    "    _resulting_df[featurename + suffix] = _resulting_df[featurename + suffix].astype('float64')\n",
    "    _resulting_df[featurename + suffix].fillna(fillmissing, inplace=True)\n",
    "\n",
    "    # Add the column to original df_train\n",
    "    df_train[featurename + suffix] = _resulting_df[featurename + suffix].round(0).astype('int64')\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# chosen_features = [ \"albumHashAndNameAndReleaseday\",\"istrack11\", \"no_artist\", \"no_composer\",\"freq_artist\", \"freq_composer\",\"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "#                    \"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "#                   \"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "#                   \"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "#                   \"isBeatAlbum\", \"isCoverAlbum\", \"artist_name_cat\",\"composers_name_cat\",\"copyright_cat\" ,\n",
    "#                   \"artist_id_min_cat\", \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\", \n",
    "#                    \"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\"isHoliday\",\n",
    "#                   \"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "#                    \"numsongInAlbum\",\"isSingleAlbum_onesong\",\"artist_mean_id\",\n",
    "#                    \"artist_std_id\" ,\"artist_count_id\",\"title_cat\",\"num_same_title\"]\n",
    "\n",
    "chosen_features = [ \"albumHashAndNameAndReleaseday\",\"istrack11\", \"no_artist\", \"no_composer\",\"freq_artist\", \"freq_composer\",\"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "                   \"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "                  \"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "                  \"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "                  \"isBeatAlbum\", \"isCoverAlbum\", \"artist_name_cat\",\"composers_name_cat\",\"copyright_cat\" ,\n",
    "                  \"artist_id_min_cat\", \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\", \n",
    "                   \"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\"isHoliday\",\n",
    "                  \"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "                   \"numsongInAlbum\",\"isSingleAlbum_onesong\",\"artist_mean_id\",\n",
    "                   \"artist_std_id\" ,\"artist_count_id\",\"title_cat\"]\n",
    "\n",
    "\n",
    "# encode_features = ['album_right', 'artist_mean_id',\"artist_id_min_cat\",\n",
    "#                      \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\"]\n",
    "\n",
    "# encode_features=[ 'artist_mean_id',\"artist_id_min_cat\",\n",
    "#                      \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\"]\n",
    "# encode_features = [f+\"_encode\" for f in encode_features]\n",
    "\n",
    "# df[encode_features] = target_encode[encode_features]\n",
    "\n",
    "# chosen_features = [ \"istrack11\", \"no_artist\", \"no_composer\",\"freq_artist\", \"freq_composer\",\"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "#                    \"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "#                   \"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "#                   \"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "#                   \"isBeatAlbum\", \"isCoverAlbum\", \"artist_name_cat\",\"composers_name_cat\",\"copyright_cat\" ,\n",
    "#                    \"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\"isHoliday\",\n",
    "#                   \"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "#                    \"numsongInAlbum\",\"isSingleAlbum_onesong\",\"artist_mean_id\",\n",
    "#                    \"artist_std_id\" ,\"artist_count_id\",\"title_cat\",\"num_same_title\"]\n",
    "\n",
    "# chosen_features =[]\n",
    "# chosen_features += encode_features\n",
    "# chosen_features = [\"album_right\",\"freq_artist\",  \"day\", \n",
    "#                      \"isBeat\",  \"num_song_release_in_final_month\",\n",
    "#                   \"length\",\"album_artist\",\n",
    "#                   \"artist_name_cat\",\"composers_name_cat\",\n",
    "#                   \"artist_id_min_cat\", \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\", \n",
    "#                    \"freq_artist_min\",\"dayofyear\", \n",
    "#                    \"numsongInAlbum\",\"artist_mean_id\",\"artist_std_id\" ,\"artist_count_id\" ]\n",
    "\n",
    "\n",
    "# chosen_features = [  \"istrack11\", \"no_artist\", \"no_composer\",\"freq_artist\", \"freq_composer\",\"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "#                    \"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "#                   \"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "#                   \"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "#                   \"isBeatAlbum\", \"isCoverAlbum\",\"copyright_cat\" ,\n",
    "#                   \"composers_id_min_cat\",\n",
    "#                    \"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\n",
    "#                   \"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "#                    \"numsongInAlbum\",\"isSingleAlbum_onesong\",\"artist_mean_id\", \"artist_std_id\" ,\"artist_count_id\"]\n",
    "\n",
    "chosen_features  += [\"predicted_label\"]\n",
    "# chosen_features += [\"mean_album_score\", \"mean_artist_min_score\"]\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "df_test = df[df.dataset==\"test\"]\n",
    "\n",
    "param = {\n",
    "    'bagging_freq': 1,          \n",
    "    'bagging_fraction': 1,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             'feature_fraction': 0.1,     'learning_rate': 0.001,\n",
    "    'max_depth': -1,             'metric':'root_mean_squared_error', 'min_data_in_leaf': 5,   \n",
    "       'num_leaves': 50,            \n",
    "    'num_threads': 8,              'tree_learner': 'serial',   'objective': 'regression',\n",
    "    'reg_alpha': 0.1002650970728192, 'reg_lambda': 0.1003427518866501,'verbosity': 1,\n",
    "    \"seed\": 99999,\n",
    "    \"use_missing\":True, \"max_bin\":2000\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=99999)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "labels= df_train.label\n",
    "# fig, axes = plt.subplots(5, 1, figsize=(10, 10*5))\n",
    "# axes = axes.flat\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train.label.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "#     if fold_ in range(0,3):\n",
    "#         continue\n",
    "    # Create lookup table\n",
    "    album_lookup_table = create_album_score_lookup_table(df_train.iloc[trn_idx])\n",
    "    artist_lookup_table = create_artist_score_lookup_table(df_train.iloc[trn_idx])\n",
    "    \n",
    "#     df_train[\"mean_album_score\"]= [assign_value_album(album_lookup_table, r) for i, r in df_train.iterrows()]\n",
    "#     df_train[\"mean_artist_min_score\"]= [assign_value_artist(artist_lookup_table, r) for i, r in df_train.iterrows()]\n",
    "    #df_train = baysianEncodeFeature(df_train, trn_idx, 'albumHashAndNameAndReleaseday', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "    #df_train = baysianEncodeFeature(df_train, trn_idx, 'artist_id_min', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "#     df_train = baysianEncodeFeature(df_train, trn_idx, 'title_truncated', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "    \n",
    "    df_train[\"predicted_label\"] = [assign_value(album_lookup_table,artist_lookup_table, r) for i, r in df_train.iterrows()]\n",
    "    print(\"Percentage null in valid:\", len(np.sum(df_train.iloc[val_idx].isnull())) / len(df_train.iloc[val_idx]))\n",
    "    df_test[\"predicted_label\"] = [assign_value(album_lookup_table,artist_lookup_table, r) for i, r in df_test.iterrows()]\n",
    "    print(\"Percentage null in test:\", len(np.sum(df_test.isnull())) / len(df_test))\n",
    "    \n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][chosen_features], label=labels.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][chosen_features], label=labels.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds =150000)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][chosen_features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(df_test[chosen_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 2000)\n",
    "df_train[\"mae\"] = np.abs(df_train.label - oof)\n",
    "df_train[\"prediction\"] =  oof\n",
    "df_train.to_csv(\"results.csv\")\n",
    "df_err = df_train.sort_values(by=\"mae\", ascending=False)\n",
    "\n",
    "df_err[[\"label\", \"prediction\", \"mae\", \"numsongInAlbum\",\"album_tmp\", \"albumHashAndNameAndReleaseday\"]].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train.albumHashAndNameAndReleaseday==2137][[\"ID\",\"artist_name\",\"m\",\"std\",\"title\",\"label\", \"prediction\", \"mae\",\"genre\" ,\"release_time\", \"composers_id\",\"numsongInAlbum\",\"album_tmp\", \"track_tmp\",\"albumHashAndNameAndReleaseday\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co chu bo\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.title==\"Người Thương Thành Người Dưng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"RMSE: {:<8.5f}\".format(sqrt(mean_squared_error(df_train.label, oof))))\n",
    "sub = pd.DataFrame({\"ID\": df_test.ID.values})\n",
    "sub[\"label\"] = predictions\n",
    "sub.to_csv(\"submission_lightgbm.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sub.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "lgb.plot_importance(clf, max_num_features=20,importance_type='gain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_features = [\"album_right\",\"freq_artist\",  \"day\", \n",
    "#                      \"isBeat\",  \"num_song_release_in_final_month\",\n",
    "#                   \"length\",\"album_artist\",\n",
    "#                   \"artist_name_cat\",\"composers_name_cat\",\n",
    "#                   \"artist_id_min_cat\", \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\", \n",
    "#                    \"freq_artist_min\",\"dayofyear\", \n",
    "#                    \"numsongInAlbum\",\"artist_mean_id\",\"artist_std_id\" ,\"artist_count_id\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
