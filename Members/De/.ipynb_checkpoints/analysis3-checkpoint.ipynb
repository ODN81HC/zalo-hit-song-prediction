{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>composers_name</th>\n",
       "      <th>composers_id</th>\n",
       "      <th>release_time</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.chords_key</th>\n",
       "      <th>tonal.chords_scale</th>\n",
       "      <th>tonal.key_edma.key</th>\n",
       "      <th>tonal.key_edma.scale</th>\n",
       "      <th>tonal.key_krumhansl.key</th>\n",
       "      <th>tonal.key_krumhansl.scale</th>\n",
       "      <th>tonal.key_temperley.key</th>\n",
       "      <th>tonal.key_temperley.scale</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>album_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1073748245</td>\n",
       "      <td>Đêm Chôn Dầu Vượt Biển</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>551</td>\n",
       "      <td>Châu Đình An</td>\n",
       "      <td>5765</td>\n",
       "      <td>2017-10-01 22:07:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>0</td>\n",
       "      <td>3c5c7e72f9112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1073751978</td>\n",
       "      <td>Mùa Thu Trong Mưa</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Trường Sa</td>\n",
       "      <td>100105</td>\n",
       "      <td>2017-10-01 20:58:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>1</td>\n",
       "      <td>f39df9c10843e3fc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          ID                   title artist_name artist_id  \\\n",
       "0      0  1073748245  Đêm Chôn Dầu Vượt Biển   Như Quỳnh       551   \n",
       "1      1  1073751978       Mùa Thu Trong Mưa  Minh Tuyết       455   \n",
       "\n",
       "  composers_name composers_id         release_time  label dataset  ...  \\\n",
       "0   Châu Đình An         5765  2017-10-01 22:07:00    7.0   train  ...   \n",
       "1      Trường Sa       100105  2017-10-01 20:58:00    3.0   train  ...   \n",
       "\n",
       "   tonal.chords_key tonal.chords_scale tonal.key_edma.key  \\\n",
       "0                 D              major                  G   \n",
       "1                 C              minor                  C   \n",
       "\n",
       "  tonal.key_edma.scale tonal.key_krumhansl.key tonal.key_krumhansl.scale  \\\n",
       "0                major                       G                     major   \n",
       "1                minor                       C                     minor   \n",
       "\n",
       "   tonal.key_temperley.key tonal.key_temperley.scale  Unnamed: 0  \\\n",
       "0                        G                     major           0   \n",
       "1                        C                     minor           1   \n",
       "\n",
       "         album_hash  \n",
       "0  3c5c7e72f9112800  \n",
       "1  f39df9c10843e3fc  \n",
       "\n",
       "[2 rows x 139 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "DATA_DIR = \"/home/vuthede/AI/zalo/zalo-hit-song-prediction/csv/\"\n",
    "TRAININFO = os.path.join(DATA_DIR, \"train_info.tsv\")\n",
    "TRAINRANK =  os.path.join(DATA_DIR, \"train_rank.csv\")\n",
    "TESTINFO = os.path.join(DATA_DIR, \"test_info.tsv\")\n",
    "SUBMISSION = os.path.join(DATA_DIR, \"submission.csv\")\n",
    "\n",
    "# Prepare data\n",
    "df_i = pd.read_csv(TRAININFO, delimiter='\\t',encoding='utf-8')\n",
    "df_r = pd.read_csv(TRAINRANK)\n",
    "df_i_train = df_i.merge(df_r, left_on='ID', right_on='ID')\n",
    "df_i_train[\"dataset\"] = \"train\"\n",
    "\n",
    "df_i_test = pd.read_csv(TESTINFO, delimiter='\\t',encoding='utf-8')\n",
    "df_i_test[\"label\"] = np.nan\n",
    "df_i_test[\"dataset\"] = \"test\"\n",
    "\n",
    "df = pd.concat([df_i_train, df_i_test])\n",
    "df_track_info = pd.read_csv(os.path.join(DATA_DIR, \"all_track_info.csv\"))\n",
    "df = df.merge(df_track_info, left_on='ID', right_on='ID')\n",
    "df_audio_features = pd.read_csv(os.path.join(DATA_DIR, \"all_track_audio_features.csv\"))\n",
    "df =df.merge(df_audio_features,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "df_album_hash = pd.read_csv(os.path.join(DATA_DIR, \"album_hash.csv\")) \n",
    "df =df.merge(df_album_hash,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "\n",
    "# Sort by ID\n",
    "df = df.sort_values(by=['ID'])\n",
    "df= df.reset_index()\n",
    "\n",
    "df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 0.24038838760298156 ratio is nan album\n",
      "There is 0.0017653981953707335 ratio is nan genre\n",
      "There is 0.24038838760298156 ratio is nan album_artist\n",
      "There is 0.0007846214201647705 ratio is nan track\n",
      "There is 0.6722244017261672 ratio is nan lyric\n",
      "2711 raw titles are identical between songs: 7485 unique titles\n",
      "After cleaning brackets etc. only 6202 unique titles remain, i.e. 1283 are highly similar titles \n",
      "In making albumHashandName, we filled in: 146 values Of the total albumHashAndName 171 nan\n",
      "In making albumHashAndNameAndReleaseday, we filled in the: 171 values remaining using the release second hash\n",
      "There is a statistically signficiant relationship between English-like title and rank. So adding feature: isEnglishLikeTitle\n"
     ]
    }
   ],
   "source": [
    "from format_features import format_features, add_artist_bestrank\n",
    "df = format_features(df)\n",
    "df = add_artist_bestrank(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from format_features import baysianEncodeFeature\n",
    "\n",
    "\n",
    "best_chosen_features = \n",
    "[\"albumHashAndNameAndReleaseday_enc\", \"istrack11\", \"no_artist\", \"no_composer\",\"freq_artist\", \"freq_composer\",\n",
    " \"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "\"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "\"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "\"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "\"isBeatAlbum\", \"isCoverAlbum\", \"artist_name_cat\",\"composers_name_cat\",\"copyright_cat\" ,\n",
    "# \"artist_id_min_cat\", \"composers_id_min_cat\",  \"artist_id_max_cat\", \"composers_id_max_cat\", \n",
    "\"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\"isHoliday\",\n",
    "\"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "\"numsongInAlbum\",\"isSingleAlbum_onesong\",\n",
    " \"artist_mean_id\", \"artist_std_id\" ,\"artist_count_id\",\"title_cat\",\"num_same_title\"]\n",
    "\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "categorical_col_names = df[all_features_in_order_list].select_dtypes(include=['category']).columns\n",
    "for colname in categorical_col_names:\n",
    "    df[colname] = df[colname].cat.codes\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chosen_features = bens_chosen_features\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "df_test = df[df.dataset==\"test\"]\n",
    "\n",
    "param = {\n",
    "    'bagging_freq': 20,          \n",
    "    'bagging_fraction': 0.95,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             'feature_fraction': 0.1,     'learning_rate': 0.001,\n",
    "    'max_depth': -1,             'metric':'root_mean_squared_error', 'min_data_in_leaf': 100, # cjha   \n",
    "       'num_leaves': 20,            \n",
    "    'num_threads': 4,              'tree_learner': 'serial',   'objective': 'regression',\n",
    "    'reg_alpha': 0.1002650970728192, 'reg_lambda': 0.1003427518866501,'verbosity': 1,\n",
    "    \"seed\": 99999\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=99999)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "labels= df_train.label\n",
    "# fig, axes = plt.subplots(5, 1, figsize=(10, 10*5))\n",
    "# axes = axes.flat\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train.label.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "    df_train = baysianEncodeFeature(df_train, trn_idx, 'albumHashAndNameAndReleaseday', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "    df_train = baysianEncodeFeature(df_train, trn_idx, 'artist_id_min', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "    df_train = baysianEncodeFeature(df_train, trn_idx, 'title_truncated', prior_weight=4, fillmissing=-1, suffix='_enc')\n",
    "\n",
    "    train_df_fold = df_train.iloc[trn_idx][chosen_features]\n",
    "    val_df_fold = df_train.iloc[val_idx][chosen_features]\n",
    "    trn_data = lgb.Dataset(train_df_fold, label=labels.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(val_df_fold, label=labels.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 20000)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][chosen_features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(df_test[chosen_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "# training's rmse: 0.428706\tvalid_1's rmse: 1.57874\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"RMSE: {:<8.5f}\".format(sqrt(mean_squared_error(df_train.label, oof))))\n",
    "sub = pd.DataFrame({\"ID\": df_test.ID.values})\n",
    "sub[\"label\"] = predictions\n",
    "sub.to_csv(\"submission_lightgbm.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "lgb.plot_importance(clf, max_num_features=20,importance_type='gain')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
