{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>composers_name</th>\n",
       "      <th>composers_id</th>\n",
       "      <th>release_time</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>tonal.tuning_frequency</th>\n",
       "      <th>tonal.tuning_nontempered_energy_ratio</th>\n",
       "      <th>tonal.chords_key</th>\n",
       "      <th>tonal.chords_scale</th>\n",
       "      <th>tonal.key_edma.key</th>\n",
       "      <th>tonal.key_edma.scale</th>\n",
       "      <th>tonal.key_krumhansl.key</th>\n",
       "      <th>tonal.key_krumhansl.scale</th>\n",
       "      <th>tonal.key_temperley.key</th>\n",
       "      <th>tonal.key_temperley.scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1073748245</td>\n",
       "      <td>Đêm Chôn Dầu Vượt Biển</td>\n",
       "      <td>Như Quỳnh</td>\n",
       "      <td>551</td>\n",
       "      <td>Châu Đình An</td>\n",
       "      <td>5765</td>\n",
       "      <td>2017-10-01 22:07:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>0.601478</td>\n",
       "      <td>D</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "      <td>G</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1073751978</td>\n",
       "      <td>Mùa Thu Trong Mưa</td>\n",
       "      <td>Minh Tuyết</td>\n",
       "      <td>455</td>\n",
       "      <td>Trường Sa</td>\n",
       "      <td>100105</td>\n",
       "      <td>2017-10-01 20:58:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.193115</td>\n",
       "      <td>0.944516</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "      <td>C</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1073835561</td>\n",
       "      <td>Rồi Ánh Trăng Tan</td>\n",
       "      <td>Lưu Bích</td>\n",
       "      <td>450</td>\n",
       "      <td>Quốc Bảo</td>\n",
       "      <td>4355</td>\n",
       "      <td>2017-11-01 18:16:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>434.193115</td>\n",
       "      <td>0.957651</td>\n",
       "      <td>Bb</td>\n",
       "      <td>major</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "      <td>D</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          ID                   title artist_name artist_id  \\\n",
       "0      0  1073748245  Đêm Chôn Dầu Vượt Biển   Như Quỳnh       551   \n",
       "1      1  1073751978       Mùa Thu Trong Mưa  Minh Tuyết       455   \n",
       "2      2  1073835561       Rồi Ánh Trăng Tan    Lưu Bích       450   \n",
       "\n",
       "  composers_name composers_id         release_time  label dataset  \\\n",
       "0   Châu Đình An         5765  2017-10-01 22:07:00    7.0   train   \n",
       "1      Trường Sa       100105  2017-10-01 20:58:00    3.0   train   \n",
       "2       Quốc Bảo         4355  2017-11-01 18:16:00    6.0   train   \n",
       "\n",
       "             ...              tonal.tuning_frequency  \\\n",
       "0            ...                          440.000000   \n",
       "1            ...                          434.193115   \n",
       "2            ...                          434.193115   \n",
       "\n",
       "  tonal.tuning_nontempered_energy_ratio tonal.chords_key tonal.chords_scale  \\\n",
       "0                              0.601478                D              major   \n",
       "1                              0.944516                C              minor   \n",
       "2                              0.957651               Bb              major   \n",
       "\n",
       "  tonal.key_edma.key tonal.key_edma.scale  tonal.key_krumhansl.key  \\\n",
       "0                  G                major                        G   \n",
       "1                  C                minor                        C   \n",
       "2                  D                minor                        D   \n",
       "\n",
       "  tonal.key_krumhansl.scale  tonal.key_temperley.key  \\\n",
       "0                     major                        G   \n",
       "1                     minor                        C   \n",
       "2                     minor                        D   \n",
       "\n",
       "   tonal.key_temperley.scale  \n",
       "0                      major  \n",
       "1                      minor  \n",
       "2                      minor  \n",
       "\n",
       "[3 rows x 137 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "DATA_DIR = \"C:\\\\Users\\\\Ben\\\\OneDrive\\\\ZaloSongComp\\\\zalo-hit-song-prediction\\\\csv\"\n",
    "TRAININFO = os.path.join(DATA_DIR, \"train_info.tsv\")\n",
    "TRAINRANK =  os.path.join(DATA_DIR, \"train_rank.csv\")\n",
    "TESTINFO = os.path.join(DATA_DIR, \"test_info.tsv\")\n",
    "SUBMISSION = os.path.join(DATA_DIR, \"submission.csv\")\n",
    "\n",
    "# Prepare data\n",
    "df_i = pd.read_csv(TRAININFO, delimiter='\\t',encoding='utf-8')\n",
    "df_r = pd.read_csv(TRAINRANK)\n",
    "df_i_train = df_i.merge(df_r, left_on='ID', right_on='ID')\n",
    "df_i_train[\"dataset\"] = \"train\"\n",
    "\n",
    "df_i_test = pd.read_csv(TESTINFO, delimiter='\\t',encoding='utf-8')\n",
    "df_i_test[\"label\"] = np.nan\n",
    "df_i_test[\"dataset\"] = \"test\"\n",
    "\n",
    "df = pd.concat([df_i_train, df_i_test])\n",
    "df_track_info = pd.read_csv(os.path.join(DATA_DIR, \"all_track_info.csv\"))\n",
    "df = df.merge(df_track_info, left_on='ID', right_on='ID')\n",
    "df_audio_features = pd.read_csv(os.path.join(DATA_DIR, \"all_track_audio_features.csv\"))\n",
    "df =df.merge(df_audio_features,left_on=\"ID\",right_on=\"ID\", how=\"left\")\n",
    "\n",
    "# Sort by ID\n",
    "df = df.sort_values(by=['ID'])\n",
    "df= df.reset_index()\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 0.24038838760298156 ratio is nan album\n",
      "There is 0.0017653981953707335 ratio is nan genre\n",
      "There is 0.24038838760298156 ratio is nan album_artist\n",
      "There is 0.0007846214201647705 ratio is nan track\n",
      "There is 0.6722244017261672 ratio is nan lyric\n"
     ]
    }
   ],
   "source": [
    "from format_features import format_features\n",
    "df = format_features(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_in_order = {\"album\":\"category\", # album name from mp3 metadata textual\n",
    "                          \"len_album_name\":\"int64\",\n",
    "                          \"isRemixAlbum\":\"category\",\n",
    "                          \"isOSTAlbum\":\"category\",\n",
    "                          \"isSingleAlbum\":\"category\",\n",
    "                          \"isBeatAlbum\":\"category\",\n",
    "                          \"isTopHitAlbum\":\"category\",\n",
    "                          \"isCoverAlbum\":\"category\",\n",
    "                          \"isEPAlbum\":\"category\",\n",
    "                          \"isLienKhucAlbum\":\"category\",\n",
    "                          \"album_name_is_title_name\":\"category\",\n",
    "                          \"artist_name\":\"category\",\n",
    "                          \"composers_name\":\"category\",\n",
    "                          \"copyright\":\"category\" ,\n",
    "                          \"artist_id_min\":\"category\",\n",
    "                          \"artist_id_max\":\"category\", \n",
    "                          \"composers_id_min\":\"category\", \n",
    "                          \"composers_id_max\":\"category\",\n",
    "                          \"genre\":\"category\", \n",
    "                          \"album_artist\":\"category\", # album artist name\n",
    "                          \"album_artist_contain_artistname\":\"category\",\n",
    "                          \"track\":\"float64\", # float between 0 and 1 representing track_num/total_tracks\n",
    "                          \"istrack11\":\"category\", # 1 if first track\n",
    "                          # \"lyric\":\"string\" # Not a trainable feature\n",
    "                          \"islyric\":\"category\",\n",
    "                          \"num_line_lyric\":\"int64\",\n",
    "                          \"no_artist\":\"int64\",\n",
    "                          \"no_composer\":\"int64\",\n",
    "                          #\"datetime\":\"datetime64\", # Not a trainable feature\n",
    "                          \"day\":\"category\",\n",
    "                          \"month\":\"category\",\n",
    "                          \"year\":\"category\",\n",
    "                          \"hour\":\"category\",\n",
    "                          \"dayofyear\":\"category\",\n",
    "                          \"weekday\":\"category\",\n",
    "                          \"isHoliday\":\"category\",\n",
    "                          \"len_of_songname\":\"int64\",\n",
    "                          \"isRemix\":\"category\",\n",
    "                          \"isOST\":\"category\",\n",
    "                          \"isBeat\":\"category\",\n",
    "                          \"isVersion\":\"category\",\n",
    "                          \"isCover\":\"category\",\n",
    "                          \"isLienKhuc\":\"category\",\n",
    "                          \"day_release\":\"int64\", # the specific day of the day across all days (> 365)  \n",
    "                          \"datetimeIs_month_end\":\"category\",\n",
    "                          \"datetimeIs_month_start\":\"category\",\n",
    "                          \"datetimeIs_quarter_end\":\"category\",\n",
    "                          \"datetimeIs_quarter_start\":\"category\",\n",
    "                          \"datetimeIs_year_end\":\"category\",\n",
    "                          \"datetimeIs_year_start\":\"category\",\n",
    "                          \"datetimeDayofweek\":\"category\",\n",
    "                         \n",
    "                          ####\n",
    "                          #Features those that require \"global\" knowledge beyond that example\n",
    "                          ####\n",
    "                          \"album_right\":\"category\", # a different representaion of \"album\" based on release time - can be combined with it, and using \n",
    "                          \"numsongInAlbum\":\"category\",\n",
    "                          \"isSingleAlbum_onesong\":\"category\",\n",
    "                          \"num_song_released_that_week\":'int64',\n",
    "                          \"num_song_release_in_final_month\":\"int64\",  \n",
    "                          \"freq_artist\":\"int64\",  # number of times the unique artist string is present in dataset\n",
    "                          \"freq_artist_min\":\"int64\", # number of times the first listed artist is present in dataset\n",
    "                          \"num_album_per_min_artist\":\"int64\",\n",
    "                          \"num_album_per_min_composer\":\"int64\",\n",
    "                          \"length\":\"float64\", # length of the song (s?)\n",
    "                          \"freq_composer_min\":\"int64\",       \n",
    "                          \"tonal.chords_key\":\"category\",\n",
    "                          \"tonal.chords_scale\":\"category\",\n",
    "                            }\n",
    "not_included_columns = set(df.columns) - set([i for i in all_features_in_order.keys()]) - set([\"tonal.chords_key\", \"tonal.chords_scale\"])\n",
    "audio_feature_names = sorted([i for i in not_included_columns if i.split(\".\")[0] == 'tonal'\n",
    "        or  i.split(\".\")[0] == 'rhythm'\n",
    "        or  i.split(\".\")[0]=='lowlevel'])\n",
    "pd.set_option('display.max_columns', 500)\n",
    "audio_feature_names_dict = {name:\"float64\" for name in audio_feature_names}\n",
    "audio_feature_names_dict[\"tonal.chords_key\"] = \"category\"\n",
    "audio_feature_names_dict[\"tonal.chords_scale\"] = \"category\"\n",
    "audio_feature_names_dict[\"tonal.key_edma.key\"] = \"category\"\n",
    "audio_feature_names_dict[\"tonal.key_edma.scale\"] = \"category\"\n",
    "audio_feature_names_dict[\"tonal.key_krumhansl.key\"] = \"category\"\n",
    "audio_feature_names_dict[\"tonal.key_krumhansl.scale\"] = \"category\"\n",
    "audio_feature_names_dict[\"tonal.key_temperley.key\"] = \"category\"\n",
    "audio_feature_names_dict[\"tonal.key_temperley.scale\"] = \"category\"\n",
    "all_features_in_order.update(audio_feature_names_dict)\n",
    "\n",
    "all_features_in_order_list = list(all_features_in_order.keys())\n",
    "for feat_name, feat_type in all_features_in_order.items():\n",
    "    try:\n",
    "        df[feat_name] = df[feat_name].astype(feat_type)\n",
    "    except ValueError:\n",
    "        \n",
    "        print(feat_name, feat_type)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: lowlevel.spectral_complexity.mean, dtype: float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df_fold[train_df_fold.isnull().any(axis=1)]['lowlevel.spectral_complexity.mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rhythm.bpm_histogram_second_peak_spread          0.000000\n",
       "lowlevel.dissonance.stdev                        0.000000\n",
       "lowlevel.erbbands_crest.mean                     0.000000\n",
       "lowlevel.erbbands_spread.stdev                   0.000146\n",
       "tonal.chords_strength.stdev                      0.000439\n",
       "tonal.key_temperley.strength                     0.000440\n",
       "lowlevel.silence_rate_20dB.stdev                 0.000465\n",
       "lowlevel.average_loudness                        0.000505\n",
       "lowlevel.erbbands_skewness.stdev                 0.000509\n",
       "no_composer                                      0.000603\n",
       "lowlevel.loudness_ebu128.loudness_range          0.000686\n",
       "lowlevel.spectral_energyband_middle_low.stdev    0.000930\n",
       "lowlevel.loudness_ebu128.short_term.stdev        0.000955\n",
       "tonal.tuning_equal_tempered_deviation            0.001028\n",
       "tonal.chords_number_rate                         0.001043\n",
       "lowlevel.spectral_energyband_low.stdev           0.001087\n",
       "lowlevel.erbbands_kurtosis.stdev                 0.001123\n",
       "lowlevel.loudness_ebu128.momentary.stdev         0.001176\n",
       "rhythm.bpm                                       0.001199\n",
       "lowlevel.zerocrossingrate.stdev                  0.001218\n",
       "lowlevel.spectral_rolloff.stdev                  0.001435\n",
       "lowlevel.hfc.stdev                               0.001565\n",
       "rhythm.bpm_histogram_second_peak_bpm             0.001592\n",
       "lowlevel.spectral_spread.mean                    0.001672\n",
       "tonal.hpcp_crest.mean                            0.001957\n",
       "lowlevel.loudness_ebu128.short_term.mean         0.002096\n",
       "tonal.key_edma.strength                          0.002363\n",
       "lowlevel.spectral_energyband_high.mean           0.002442\n",
       "lowlevel.erbbands_skewness.mean                  0.002458\n",
       "tonal.hpcp_entropy.stdev                         0.003214\n",
       "                                                   ...   \n",
       "rhythm.beats_loudness.stdev                      0.014777\n",
       "lowlevel.erbbands_kurtosis.mean                  0.014806\n",
       "lowlevel.barkbands_crest.stdev                   0.014900\n",
       "lowlevel.spectral_centroid.mean                  0.015403\n",
       "lowlevel.spectral_complexity.stdev               0.015550\n",
       "lowlevel.barkbands_skewness.stdev                0.015584\n",
       "lowlevel.spectral_strongpeak.stdev               0.015847\n",
       "lowlevel.barkbands_flatness_db.stdev             0.015932\n",
       "lowlevel.barkbands_skewness.mean                 0.016111\n",
       "lowlevel.spectral_complexity.mean                0.017122\n",
       "lowlevel.spectral_energyband_middle_low.mean     0.017274\n",
       "no_artist                                        0.017468\n",
       "rhythm.bpm_histogram_second_peak_weight          0.017535\n",
       "length                                           0.018892\n",
       "lowlevel.erbbands_flatness_db.stdev              0.019363\n",
       "len_album_name                                   0.020066\n",
       "track                                            0.021919\n",
       "lowlevel.barkbands_kurtosis.mean                 0.021985\n",
       "rhythm.onset_rate                                0.022589\n",
       "lowlevel.spectral_energyband_middle_high.mean    0.022620\n",
       "lowlevel.barkbands_kurtosis.stdev                0.023495\n",
       "rhythm.beats_count                               0.026494\n",
       "lowlevel.pitch_salience.stdev                    0.034296\n",
       "num_album_per_min_composer                       0.034546\n",
       "freq_composer_min                                0.056150\n",
       "num_album_per_min_artist                         0.116878\n",
       "freq_artist                                      0.165879\n",
       "freq_artist_min                                  0.176523\n",
       "num_song_release_in_final_month                  0.197928\n",
       "day_release                                      0.330020\n",
       "Length: 125, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "n_splits=3\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=99999)\n",
    "\n",
    "labels= df_train.label\n",
    "numeric_data = df_train[all_features_in_order_list].select_dtypes(include=['float64', 'int64'])\n",
    "numeric_information_series = pd.Series( {name:0 for name in numeric_data.columns})\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train.label.values)):\n",
    "    print(\"cross validation \", fold_)\n",
    "    train_df_fold = numeric_data.iloc[trn_idx]\n",
    "    label_fold = df_train.label.iloc[trn_idx]\n",
    "    train_df_fold.fillna(train_df_fold.mean(), inplace=True)  # data leakage unless done inside folds\n",
    "    numeric_information = {}\n",
    "    numeric_information = {name:score for (score, name) in zip(mutual_info_regression(train_df_fold, label_fold), numeric_data.columns)}\n",
    "    numeric_information_series = numeric_information_series + pd.Series(numeric_information)\n",
    "(pd.Series(numeric_information_series)/n_splits).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lowlevel.barkbands_kurtosis.stdev', 'rhythm.beats_count',\n",
       "       'lowlevel.pitch_salience.stdev', 'num_album_per_min_composer',\n",
       "       'freq_composer_min', 'num_album_per_min_artist', 'freq_artist',\n",
       "       'freq_artist_min', 'num_song_release_in_final_month', 'day_release'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.Series(numeric_information_series)/n_splits).sort_values()[-20:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Zing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-44b01e6596ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mnumeric_information\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnumeric_information\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmutual_info_classif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mnumeric_information_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_information_series\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_information\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_information_series\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[1;32m--> 451\u001b[1;33m                         copy, random_state)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\sklearn\\feature_selection\\mutual_info_.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    245\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2014.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gymai\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Zing'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "n_splits=3\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=99999)\n",
    "\n",
    "labels= df_train.label\n",
    "numeric_data = df_train[all_features_in_order_list].select_dtypes(include=['category'])\n",
    "numeric_information_series = pd.Series( {name:0 for name in numeric_data.columns})\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train.label.values)):\n",
    "    print(\"cross validation \", fold_)\n",
    "    train_df_fold = numeric_data.iloc[trn_idx]\n",
    "    label_fold = df_train.label.iloc[trn_idx]\n",
    "    train_df_fold.fillna(train_df_fold.mean(), inplace=True)  # data leakage unless done inside folds\n",
    "    numeric_information = {}\n",
    "    numeric_information = {name:score for (score, name) in zip(mutual_info_regression(train_df_fold, label_fold), numeric_data.columns)}\n",
    "    numeric_information_series = numeric_information_series + pd.Series(numeric_information)\n",
    "(pd.Series(numeric_information_series)/n_splits).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lowlevel.barkbands_kurtosis.stdev', 'rhythm.beats_count',\n",
       "       'lowlevel.pitch_salience.stdev', 'num_album_per_min_composer',\n",
       "       'freq_composer_min', 'num_album_per_min_artist', 'freq_artist',\n",
       "       'freq_artist_min', 'num_song_release_in_final_month', 'day_release'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.Series(numeric_information_series)/n_splits).sort_values()[-10:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "chosen_features = [\"album_right\", \"istrack11\", \"no_artist\", \"freq_artist\", \"freq_composer\",\"year\", \"month\",\"hour\", \"day\", \"len_of_songname\", \n",
    "                   \"isRemix\", \"isOST\", \"isBeat\", \"isVersion\", \"isCover\",  \"num_song_release_in_final_month\",\n",
    "                  \"length\", \"genre\", \"track\",\"album_artist\", \"islyric\", \"album_artist_contain_artistname\",\n",
    "                  \"len_album_name\", \"isRemixAlbum\", \"isOSTAlbum\", \"isSingleAlbum\", \"album_name_is_title_name\",\n",
    "                  \"isBeatAlbum\", \"isCoverAlbum\", \"artist_name\",\"composers_name\",\"copyright\" ,\n",
    "                  \"artist_id_min\", \"composers_id_min\",  \"artist_id_max\", \"composers_id_max\", \n",
    "                   \"freq_artist_min\", \"freq_composer_min\",\"dayofyear\",\"weekday\",\"isHoliday\",\n",
    "                  \"num_album_per_min_artist\", \"num_album_per_min_composer\", \n",
    "                   \"numsongInAlbum\",\"isSingleAlbum_onesong\",\n",
    "                   # added following and removed no_composer which carries no mutual info. changed min_data_in_leaf to 100 to reduce overfitting\n",
    "                   \"rhythm.bpm_histogram_second_peak_weight\",\"day_release\",\"lowlevel.barkbands_kurtosis.stdev\",\n",
    "                  \"rhythm.beats_count\", \"lowlevel.pitch_salience.stdev\", \"lowlevel.erbbands_flatness_db.stdev\"]\n",
    "df = df.copy()\n",
    "categorical_col_names = df_train[all_features_in_order_list].select_dtypes(include=['category']).columns\n",
    "for colname in categorical_col_names:\n",
    "    df[colname] = df[colname].cat.codes\n",
    "\n",
    "df_train = df[df.dataset==\"train\"]\n",
    "df_test = df[df.dataset==\"test\"]\n",
    "\n",
    "param = {\n",
    "    'bagging_freq': 20,          \n",
    "    'bagging_fraction': 0.95,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             'feature_fraction': 0.1,     'learning_rate': 0.001,\n",
    "    'max_depth': -1,             'metric':'root_mean_squared_error', 'min_data_in_leaf': 100, # cjha   \n",
    "       'num_leaves': 50,            \n",
    "    'num_threads': 4,              'tree_learner': 'serial',   'objective': 'regression',\n",
    "    'reg_alpha': 0.1002650970728192, 'reg_lambda': 0.1003427518866501,'verbosity': 1,\n",
    "    \"seed\": 99999\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=99999)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "labels= df_train.label\n",
    "# fig, axes = plt.subplots(5, 1, figsize=(10, 10*5))\n",
    "# axes = axes.flat\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train.label.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][chosen_features], label=labels.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][chosen_features], label=labels.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 20000)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][chosen_features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(df_test[chosen_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "# training's rmse: 0.428706\tvalid_1's rmse: 1.57874\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gymai]",
   "language": "python",
   "name": "conda-env-gymai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
